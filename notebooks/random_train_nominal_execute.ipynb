{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/am/tamp_multi_agent/env_isaaclab/lib/python3.10/site-packages/gym/wrappers/monitoring/video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List,Dict\n",
    "\n",
    "import copy\n",
    "import itertools \n",
    "import time\n",
    "from tampura.policies.policy import save_config, RolloutHistory, save_run_data\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tampura.environment import TampuraEnv\n",
    "from tampura.spec import ProblemSpec\n",
    "from tampura.structs import (\n",
    "    AbstractBelief,\n",
    "    ActionSchema,\n",
    "    StreamSchema,\n",
    "    AliasStore,\n",
    "    Belief,\n",
    "    NoOp,\n",
    "    Predicate,\n",
    "    State,\n",
    "    effect_from_execute_fn,\n",
    "    Observation,\n",
    "    AbstractBeliefSet,\n",
    ")\n",
    "import logging \n",
    "from tampura.symbolic import OBJ, Atom, ForAll, Not, Exists, Or, And, OneOf, eval_expr\n",
    "from tampura.policies.tampura_policy import TampuraPolicy\n",
    "from tampura.config.config import load_config, setup_logger\n",
    "\n",
    "ROB = \"robot_\"\n",
    "REG = \"region_\"\n",
    "MUG = \"mug\"\n",
    "DOOR = \"door\"\n",
    "REGIONS = [f\"{REG}{MUG}\",f\"{REG}{DOOR}\",f\"{REG}stable_mug\"]\n",
    "ACTION_NAMES = [\"transit_action\",\"transfer_action\",\"pick_action\",\"place_action\",\"open_action\",\"close_action\",\"nothing_action\"]\n",
    "\n",
    "# problem specification: try with just one robot to demonstrate how overall cost increases\n",
    "ROBOTS=[f\"{ROB}1\",f\"{ROB}2\"]\n",
    "ROB_REGIONS = {ROBOTS[0]:REGIONS[-1],ROBOTS[1]:REGIONS[-1]} # long horizon: combinatorial explosion\n",
    "# ROB_REGIONS = {ROBOTS[0]:REGIONS[1],ROBOTS[1]:REGIONS[0]} # short horizon: kind of works?\n",
    "OBJ_REGIONS={MUG:REGIONS[0]}\n",
    "\n",
    "# Test \n",
    "GOAL = And([Exists(Atom(\"holding\",[\"?rob\",MUG]),[\"?rob\"],[\"robot\"]),Not(Atom(\"open\",[DOOR]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralized planner\n",
    "# State of the environment\n",
    "\n",
    "# Belief space\n",
    "class CentralBelief(Belief):\n",
    "    def __init__(self, holding={},open_door=False,rob_regions={},obj_regions={},turn=ROBOTS[0]):\n",
    "        # true state\n",
    "        self.holding = holding\n",
    "        self.open_door = open_door\n",
    "        self.rob_regions = rob_regions\n",
    "        self.obj_regions = obj_regions\n",
    "        self.turn = turn\n",
    "        \n",
    "\n",
    "    def update(self, a, o, s):\n",
    "        \n",
    "        # dictionary mutations are IN-PLACE!!! use .copy()!!\n",
    "        holding = self.holding.copy() \n",
    "        open_door = self.open_door\n",
    "        rob_regions = self.rob_regions.copy()\n",
    "        obj_regions = self.obj_regions.copy()\n",
    "        turn = self.turn\n",
    "        \n",
    "        \n",
    "        # BE CAREFUL: update names if you change action schema names\n",
    "        if a.name == \"pick\":\n",
    "            holding[a.args[0]]=[a.args[1]]\n",
    "            obj_regions[a.args[1]]=\"\"\n",
    "        elif a.name == \"place\":\n",
    "            holding[a.args[0]]=[]\n",
    "            obj_regions[a.args[1]]=a.args[2]\n",
    "        elif a.name == \"transit\" or a.name == \"transfer\":\n",
    "            rob_regions[a.args[0]]=a.args[2]\n",
    "        elif a.name == \"open\":\n",
    "            open_door=True\n",
    "        elif a.name == \"close\":\n",
    "            open_door=False\n",
    "        \n",
    "        turn=a.args[-1] # turn of the agent\n",
    "            \n",
    "        return CentralBelief(holding=holding,open_door=open_door,rob_regions=rob_regions,obj_regions=obj_regions,turn=turn)\n",
    "\n",
    "    def abstract(self, store: AliasStore):\n",
    "        \n",
    "        ab = []\n",
    "        \n",
    "        # true state\n",
    "        for rob in self.holding.keys():\n",
    "            ab += [Atom(\"holding\",[rob,obj]) for obj in self.holding[rob]]\n",
    "        for rob in self.rob_regions.keys():\n",
    "            ab += [Atom(\"in_rob\",[rob,self.rob_regions[rob]])]\n",
    "        for obj in self.obj_regions.keys():\n",
    "            if self.obj_regions[obj] !=\"\":\n",
    "                ab += [Atom(\"in_obj\",[obj,self.obj_regions[obj]])]\n",
    "        if self.open_door:\n",
    "            ab += [Atom(\"open\",[DOOR])]\n",
    "        \n",
    "        ab += [Atom(\"turn\",[self.turn])]\n",
    "            \n",
    "        return AbstractBelief(ab)\n",
    "\n",
    "    # def vectorize(self):\n",
    "    #     return np.array([int(obj in self.holding) for obj in OBJECTS])\n",
    "      \n",
    "\n",
    "def deterministic_execute_fn(a, b, s, store):\n",
    "    return State(), Observation()\n",
    "    \n",
    "def deterministic_effects_fn(a, b, store):\n",
    "    o = Observation()    \n",
    "    new_belief=b.update(a,o,store)\n",
    "    return AbstractBeliefSet.from_beliefs([new_belief], store)\n",
    "\n",
    "# Set up environment dynamics\n",
    "class ToyDiscreteCentral(TampuraEnv):\n",
    "    \n",
    "    def initialize(self,holding,open_door,rob_regions,obj_regions,turn):\n",
    "        \n",
    "        store = AliasStore()\n",
    "        \n",
    "        for rob in ROBOTS:\n",
    "            \n",
    "            store.set(rob, rob, \"robot\")\n",
    "        # store.set(ego,ego,\"robot\")\n",
    "            \n",
    "        for region in REGIONS:\n",
    "            store.set(region, region, \"region\")\n",
    "        \n",
    "        store.set(MUG, MUG, \"physical\")\n",
    "        store.set(DOOR, DOOR, \"door\")\n",
    "        \n",
    "        store.certified.append(Atom(\"stable\",[MUG,REGIONS[0]]))\n",
    "        store.certified.append(Atom(\"stable\",[MUG,REGIONS[2]]))\n",
    "\n",
    "        b = CentralBelief(holding=holding,open_door=open_door,rob_regions=rob_regions,obj_regions=obj_regions,turn=turn)\n",
    "\n",
    "        return b, store\n",
    "\n",
    "    def get_problem_spec(self) -> ProblemSpec:\n",
    "        \n",
    "\n",
    "        predicates = [\n",
    "            \n",
    "            Predicate(\"holding\", [\"robot\",\"physical\"]),\n",
    "            Predicate(\"stable\",[\"physical\",\"region\"]),\n",
    "            Predicate(\"in_rob\",[\"robot\",\"region\"]),\n",
    "            Predicate(\"in_obj\",[\"physical\",\"region\"]),\n",
    "            Predicate(\"open\",[\"door\"]),\n",
    "            Predicate(\"turn\",[\"robot\"])\n",
    "        ] \n",
    "        \n",
    "        # modify preconditions, effects and execute functions for observation\n",
    "        action_schemas = [\n",
    "            \n",
    "            # ego-agent\n",
    "            ActionSchema(\n",
    "                name=\"pick\",\n",
    "                inputs=[\"?rob1\",\"?obj1\",\"?reg1\",\"?rob2\"],\n",
    "                input_types=[\"robot\",\"physical\",\"region\",\"robot\"],\n",
    "                preconditions=[Atom(\"turn\",[\"?rob1\"]),Not(Atom(\"turn\",[\"?rob2\"])),\n",
    "                               Or([Not(Atom(\"in_obj\",[\"?obj1\",REGIONS[0]])),And([Atom(\"in_obj\",[\"?obj1\",REGIONS[0]]),Atom(\"open\",[DOOR])])]), # TODO: modify!! accesibility of mug: derived predicate\n",
    "                               Atom(\"in_obj\",[\"?obj1\",\"?reg1\"]), # object is in region from where pick is attempted\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]), # robot is in region from where pick is attempted\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"])), # robot hand is free\n",
    "                               ],\n",
    "                effects=[Atom(\"holding\",[\"?rob1\",\"?obj1\"]),Not(Atom(\"in_obj\",[\"?obj1\",\"?reg1\"])),\n",
    "                         Atom(\"turn\",[\"?rob2\"]),Not(Atom(\"turn\",[\"?rob1\"]))], # deterministic\n",
    "                effects_fn=deterministic_effects_fn,\n",
    "                execute_fn=deterministic_execute_fn,\n",
    "            ),\n",
    "            \n",
    "            \n",
    "            ActionSchema(\n",
    "                name=\"place\",\n",
    "                inputs=[\"?rob1\",\"?obj1\",\"?reg1\",\"?rob2\"],\n",
    "                input_types=[\"robot\",\"physical\",\"region\",\"robot\"],\n",
    "                preconditions=[Atom(\"turn\",[\"?rob1\"]),Not(Atom(\"turn\",[\"?rob2\"])),\n",
    "                               Or([Not(Atom(\"in_rob\",[\"?rob1\",REGIONS[0]])),And([Atom(\"in_rob\",[\"?rob1\",REGIONS[0]]),Atom(\"open\",[DOOR])])]), # TODO: modify!! accessibility of region\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]), # robot is in region where place is attempted\n",
    "                               Atom(\"holding\",[\"?rob1\",\"?obj1\"]), # robot is holding the object that is to be placed \n",
    "                               Atom(\"stable\",[\"?obj1\",\"?reg1\"]), # region where place is attempted is stable\n",
    "                               ],\n",
    "                effects=[Not(Atom(\"holding\",[\"?rob1\",\"?obj1\"])),Atom(\"in_obj\",[\"?obj1\",\"?reg1\"]),\n",
    "                         Atom(\"turn\",[\"?rob2\"]),Not(Atom(\"turn\",[\"?rob1\"]))], # deterministic \n",
    "                effects_fn=deterministic_effects_fn,\n",
    "                execute_fn=deterministic_execute_fn,\n",
    "            ),\n",
    "            \n",
    "\n",
    "            ActionSchema(\n",
    "                name=\"transit\",\n",
    "                inputs=[\"?rob1\",\"?reg1\",\"?reg2\",\"?rob2\"],\n",
    "                input_types=[\"robot\",\"region\",\"region\",\"robot\"],\n",
    "                preconditions=[Atom(\"turn\",[\"?rob1\"]),Not(Atom(\"turn\",[\"?rob2\"])),\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]),\n",
    "                               Not(Atom(\"in_rob\",[\"?rob1\",\"?reg2\"])),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"])), # robot hand is free\n",
    "                               ],\n",
    "                effects=[Not(Atom(\"in_rob\",[\"?rob1\",\"?reg1\"])),Atom(\"in_rob\",[\"?rob1\",\"?reg2\"]),\n",
    "                         Atom(\"turn\",[\"?rob2\"]),Not(Atom(\"turn\",[\"?rob1\"]))],\n",
    "                effects_fn=deterministic_effects_fn,\n",
    "                execute_fn=deterministic_execute_fn,\n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"transfer\",\n",
    "                inputs=[\"?rob1\",\"?reg1\",\"?reg2\",\"?obj1\",\"?rob2\"],\n",
    "                input_types=[\"robot\",\"region\",\"region\",\"physical\",\"robot\"],\n",
    "                preconditions=[Atom(\"turn\",[\"?rob1\"]),Not(Atom(\"turn\",[\"?rob2\"])),\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]),\n",
    "                               Not(Atom(\"in_rob\",[\"?rob1\",\"?reg2\"])),\n",
    "                               Atom(\"holding\",[\"?rob1\",\"?obj1\"])],\n",
    "                effects=[Not(Atom(\"in_rob\",[\"?rob1\",\"?reg1\"])),Atom(\"in_rob\",[\"?rob1\",\"?reg2\"]),\n",
    "                         Atom(\"turn\",[\"?rob2\"]),Not(Atom(\"turn\",[\"?rob1\"]))],\n",
    "                effects_fn=deterministic_effects_fn,\n",
    "                execute_fn=deterministic_execute_fn,\n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"open\",\n",
    "                inputs=[\"?rob1\",\"?rob2\"],\n",
    "                input_types=[\"robot\",\"robot\"],\n",
    "                preconditions=[Atom(\"turn\",[\"?rob1\"]),Not(Atom(\"turn\",[\"?rob2\"])),\n",
    "                               Not(Atom(\"open\",[DOOR])),\n",
    "                               Atom(\"in_rob\",[\"?rob1\",REGIONS[1]]),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"]))],\n",
    "                effects=[Atom(\"open\",[DOOR]),\n",
    "                         Atom(\"turn\",[\"?rob2\"]),Not(Atom(\"turn\",[\"?rob1\"]))],\n",
    "                effects_fn=deterministic_effects_fn,\n",
    "                execute_fn=deterministic_execute_fn,\n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"close\",\n",
    "                inputs=[\"?rob1\",\"?rob2\"],\n",
    "                input_types=[\"robot\",\"robot\"],\n",
    "                preconditions=[Atom(\"turn\",[\"?rob1\"]),Not(Atom(\"turn\",[\"?rob2\"])), \n",
    "                               Atom(\"open\",[DOOR]),\n",
    "                               Atom(\"in_rob\",[\"?rob1\",REGIONS[1]]),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"]))],\n",
    "                effects=[Not(Atom(\"open\",[DOOR])),\n",
    "                         Atom(\"turn\",[\"?rob2\"]),Not(Atom(\"turn\",[\"?rob1\"]))],\n",
    "                effects_fn=deterministic_effects_fn,\n",
    "                execute_fn=deterministic_execute_fn,\n",
    "\n",
    "            ),\n",
    "            \n",
    "            ActionSchema(\n",
    "                name=\"nothing\",\n",
    "                inputs=[\"?rob1\",\"?rob2\"],\n",
    "                input_types=[\"robot\",\"robot\"],\n",
    "                preconditions=[Atom(\"turn\",[\"?rob1\"]),Not(Atom(\"turn\",[\"?rob2\"]))],\n",
    "                effects=[Atom(\"turn\",[\"?rob2\"]),Not(Atom(\"turn\",[\"?rob1\"]))],\n",
    "                effects_fn=deterministic_effects_fn,\n",
    "                execute_fn=deterministic_execute_fn,\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        \n",
    "        reward = GOAL\n",
    "\n",
    "        spec = ProblemSpec(\n",
    "            predicates=predicates,\n",
    "            action_schemas=action_schemas,\n",
    "            reward=reward,\n",
    "        )\n",
    "\n",
    "        return spec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "# Planner\n",
    "cfg = load_config(config_file=\"../tampura/config/default.yml\")\n",
    "\n",
    "# Set some print options to print out abstract belief, action, observation, and reward\n",
    "cfg[\"print_options\"] = \"ab,a,o,r\"\n",
    "cfg[\"vis_graph\"] = True\n",
    "# batch size 100, num samples 500 num skeletons 100 works best!!\n",
    "cfg[\"batch_size\"] = 100 #100 \n",
    "cfg[\"num_samples\"] = 100#500\n",
    "cfg[\"max_steps\"] = 15\n",
    "cfg[\"num_skeletons\"] = 10\n",
    "cfg[\"flat_sample\"] = False # TODO: check; may cause progressive widening\n",
    "cfg['save_dir'] = os.getcwd()+\"/runs/run{}\".format(time.time())\n",
    "\n",
    "# cfg['from_scratch'] = False # imp: re-use!!! but graph gets too big\n",
    "\n",
    "# TODO: check - can we reuse the same environment for both agents?\n",
    "# for robot1\n",
    "# Initialize environment\n",
    "env = ToyDiscreteCentral(config=cfg)\n",
    "b0, store= env.initialize(holding={ROBOTS[0]:[],ROBOTS[1]:[]},open_door=False,\n",
    "                          rob_regions={ROBOTS[0]:REGIONS[-1],ROBOTS[1]:REGIONS[-1]},\n",
    "                          obj_regions={MUG:REGIONS[0]},turn=ROBOTS[0])\n",
    "\n",
    "# Set up logger to print info\n",
    "setup_logger(cfg[\"save_dir\"], logging.INFO)\n",
    "\n",
    "# Initialize the policy\n",
    "planner = TampuraPolicy(config = cfg, problem_spec = env.problem_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========t=0==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='turn', args=['robot_1']), Atom(pred_name='in_rob', args=['robot_1', 'region_stable_mug']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='in_rob', args=['robot_2', 'region_stable_mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] Flat Action Parameter Sampling\n",
      "[TampuraPolicy] Outcome Sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 161.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TampuraPolicy] MDP Solving\n",
      "Action: transit(robot_1, region_stable_mug, region_door, robot_2)\n",
      "Observation: Observation()\n",
      "\n",
      "==========t=1==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='turn', args=['robot_2']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='in_rob', args=['robot_2', 'region_stable_mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: transit(robot_2, region_stable_mug, region_mug, robot_1)\n",
      "Observation: Observation()\n",
      "\n",
      "==========t=2==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='turn', args=['robot_1']), Atom(pred_name='in_rob', args=['robot_2', 'region_mug']), Atom(pred_name='in_obj', args=['mug', 'region_mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n",
      "Action: open(robot_1, robot_2)\n",
      "Observation: Observation()\n",
      "\n",
      "==========t=3==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='in_rob', args=['robot_2', 'region_mug']), Atom(pred_name='turn', args=['robot_2']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='open', args=['door'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n",
      "Action: pick(robot_2, mug, region_mug, robot_1)\n",
      "Observation: Observation()\n",
      "\n",
      "==========t=4==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='holding', args=['robot_2', 'mug']), Atom(pred_name='turn', args=['robot_1']), Atom(pred_name='in_rob', args=['robot_2', 'region_mug']), Atom(pred_name='open', args=['door'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n",
      "Action: close(robot_1, robot_2)\n",
      "Observation: Observation()\n",
      "goal achieved\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "b=b0\n",
    "assert env.problem_spec.verify(store)\n",
    "\n",
    "save_config(planner.config, planner.config[\"save_dir\"])\n",
    "\n",
    "history = RolloutHistory(planner.config)\n",
    "st = time.time()\n",
    "for step in range(100):\n",
    "# while True:\n",
    "    s = copy.deepcopy(env.state)\n",
    "    a_b = b.abstract(store)\n",
    "    reward = env.problem_spec.get_reward(a_b, store)\n",
    "    if reward:\n",
    "        print(\"goal achieved\")\n",
    "        break\n",
    "\n",
    "    logging.info(\"\\n\" + (\"=\" * 10) + \"t=\" + str(step) + (\"=\" * 10))\n",
    "    if \"s\" in planner.print_options:\n",
    "        logging.info(\"State: \" + str(s))\n",
    "    if \"b\" in planner.print_options:\n",
    "        logging.info(\"Belief: \" + str(b))\n",
    "    if \"ab\" in planner.print_options:\n",
    "        logging.info(\"Abstract Belief: \" + str(a_b))\n",
    "    if \"r\" in planner.print_options:\n",
    "        logging.info(\"Reward: \" + str(reward))\n",
    "    \n",
    "    \n",
    "    action, info, store = planner.get_action(b, store) # should only call effects functions!!??\n",
    "    \n",
    "    \n",
    "    if \"a\" in planner.print_options:\n",
    "        logging.info(\"Action: \" + str(action))\n",
    "\n",
    "    if action.name == \"no-op\":\n",
    "        bp = copy.deepcopy(b)\n",
    "        observation = None\n",
    "    else:\n",
    "        observation = env.step(action, b, store) # should call execute function\n",
    "        bp = b.update(action, observation, store)\n",
    "\n",
    "        if planner.config[\"vis\"]:\n",
    "            env.vis_updated_belief(bp, store)\n",
    "\n",
    "    a_bp = bp.abstract(store)\n",
    "    history.add(s, b, a_b, action, observation, reward, info, store, time.time() - st)\n",
    "\n",
    "    reward = env.problem_spec.get_reward(a_bp, store)\n",
    "    \n",
    "    if \"o\" in planner.print_options:\n",
    "        logging.info(\"Observation: \" + str(observation))\n",
    "    if \"sp\" in planner.print_options:\n",
    "        logging.info(\"Next State: \" + str(env.state))\n",
    "    if \"bp\" in planner.print_options:\n",
    "        logging.info(\"Next Belief: \" + str(bp))\n",
    "    if \"abp\" in planner.print_options:\n",
    "        logging.info(\"Next Abstract Belief: \" + str(a_bp))\n",
    "    if \"rp\" in planner.print_options:\n",
    "        logging.info(\"Next Reward: \" + str(reward))\n",
    "\n",
    "    # update the belief\n",
    "    b = bp\n",
    "\n",
    "history.add(env.state, bp, a_bp, None, None, reward, info, store, time.time() - st)\n",
    "\n",
    "logging.info(\"=\" * 20)\n",
    "\n",
    "env.wrapup()\n",
    "\n",
    "if not planner.config[\"real_execute\"]:\n",
    "    save_run_data(history, planner.config[\"save_dir\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/am/tamp_multi_agent/notebooks/runs/run1748344218.7346234'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['save_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State of the environment\n",
    "@dataclass\n",
    "class EnvState(State):\n",
    "    holding: Dict[str,List[str]] = field(default_factory=lambda: {})\n",
    "    open_door: bool = field(default_factory=lambda: False)\n",
    "    rob_regions: Dict[str,str] = field(default_factory=lambda:{})\n",
    "    obj_regions: Dict[str,str] = field(default_factory=lambda:{})\n",
    "    next_actions: List[str] = field(default_factory=lambda: [])\n",
    "    \n",
    "# Observation space\n",
    "@dataclass\n",
    "class EnvObservation(Observation):\n",
    "    holding: Dict[str,List[str]] = field(default_factory=lambda: {})\n",
    "    open_door: bool = field(default_factory=lambda: False)\n",
    "    rob_regions: Dict[str,str] = field(default_factory=lambda:{})\n",
    "    obj_regions: Dict[str,str] = field(default_factory=lambda:{})\n",
    "    next_actions: List[str] = field(default_factory=lambda: [])\n",
    "\n",
    "# Belief space\n",
    "class EnvBelief(Belief):\n",
    "    def __init__(self, holding={},open_door=False,rob_regions={},obj_regions={},next_actions=[]):\n",
    "        # true state\n",
    "        self.holding = holding\n",
    "        self.open_door = open_door\n",
    "        self.rob_regions = rob_regions\n",
    "        self.obj_regions = obj_regions\n",
    "        self.next_actions = next_actions\n",
    "        \n",
    "\n",
    "    def update(self, a, o, s):\n",
    "        \n",
    "        # dictionary mutations are IN-PLACE!!! use .copy()!!\n",
    "        holding = self.holding.copy() \n",
    "        open_door = self.open_door\n",
    "        rob_regions = self.rob_regions.copy()\n",
    "        obj_regions = self.obj_regions.copy()\n",
    "        next_actions = self.next_actions\n",
    "        \n",
    "        \n",
    "        # get argument index for ego agent\n",
    "        \n",
    "        a_other_name,a_ego_name = a.name.split(\"*\")\n",
    "        \n",
    "        if a_other_name == \"transfer_other\":\n",
    "            nargs_other = 4\n",
    "        elif a_other_name == \"nothing_other\" or a_other_name == \"open_other\" or a_other_name == \"close_other\":\n",
    "            nargs_other = 1\n",
    "        else:\n",
    "            nargs_other = 3\n",
    "            \n",
    "        a_ego_args = a.args[nargs_other:]\n",
    "        \n",
    "        \n",
    "        # special cases\n",
    "        # case 1: place, pick\n",
    "        if a_other_name == \"place_other\" and a_ego_name == \"pick_ego\":\n",
    "            \n",
    "            holding = o.holding\n",
    "            obj_regions = o.obj_regions\n",
    "            \n",
    "        # case 2: open, pick\n",
    "        # case 3: open, place\n",
    "        elif (a_other_name == \"open_other\") and (a_ego_name == \"pick_ego\" or a_ego_name == \"place_ego\"):\n",
    "            \n",
    "            open_door = o.open_door\n",
    "            obj_regions = o.obj_regions\n",
    "            holding = o.holding\n",
    "            \n",
    "        # case 4: open, close\n",
    "        # case 7: close, open\n",
    "        elif (a_other_name == \"open_other\" and a_ego_name == \"close_ego\") or (a_other_name == \"close_other\" and a_ego_name == \"open_ego\"):\n",
    "            \n",
    "            open_door = o.open_door\n",
    "        \n",
    "        # case 5: close, pick\n",
    "        # case 6: close, place\n",
    "        elif a_other_name == \"close_other\" and (a_ego_name == \"pick_ego\" or a_ego_name == \"place_ego\"):\n",
    "            \n",
    "            open_door = o.open_door\n",
    "            obj_regions = o.obj_regions\n",
    "            holding = o.holding\n",
    "        \n",
    "        \n",
    "        # others \n",
    "        else: # ego: non-deterministic, other: non-deterministic\n",
    "            \n",
    "            # ego actions\n",
    "            if a_ego_name == \"transit_ego\" or a_ego_name == \"transfer_ego\": # update NOT taking place!!!\n",
    "                rob_regions[a_ego_args[0]] = o.rob_regions[a_ego_args[0]]\n",
    "                \n",
    "                    \n",
    "            elif a_ego_name == \"pick_ego\" or a_ego_name == \"place_ego\":\n",
    "                holding[a_ego_args[0]] = o.holding[a_ego_args[0]]\n",
    "                obj_regions[a_ego_args[1]] = o.obj_regions[a_ego_args[1]]\n",
    "            \n",
    "            elif a_ego_name == \"open_ego\" or a_ego_name == \"close_ego\": # open or shut door\n",
    "                open_door = o.open_door\n",
    "                \n",
    "            elif a_ego_name == \"nothing_ego\":\n",
    "                pass\n",
    "            \n",
    "            # other agent's actions     \n",
    "            if a_other_name == \"transit_other\" or a_other_name == \"transfer_other\":\n",
    "                # assumption: transit is only confusable with transit or noop\n",
    "                # assumption: transfer is only confusable with transfer or noop\n",
    "                rob_regions[a.args[0]] = o.rob_regions[a.args[0]]\n",
    "            \n",
    "            elif a_other_name == \"pick_other\" or a_other_name == \"place_other\":\n",
    "                # assumption: pick is only confusable with pick or noop\n",
    "                # assumption: place is only confusable with place or noop\n",
    "                holding[a.args[0]] = o.holding[a.args[0]]\n",
    "                obj_regions[a.args[1]] = o.obj_regions[a.args[1]]\n",
    "            \n",
    "            elif a_other_name == \"open_other\" or a_other_name == \"close_other\":\n",
    "                # assumption: open is only confusable with open or noop\n",
    "                # assumption: close is only confusable with close or noop\n",
    "                open_door = o.open_door\n",
    "            \n",
    "            elif a_other_name == \"nothing_other\":\n",
    "                # no change in state\n",
    "                pass\n",
    "           \n",
    "        next_actions = o.next_actions\n",
    "            \n",
    "        return EnvBelief(holding=holding,open_door=open_door,rob_regions=rob_regions,obj_regions=obj_regions,next_actions=next_actions)\n",
    "\n",
    "    def abstract(self, store: AliasStore):\n",
    "        \n",
    "        ab = []\n",
    "        \n",
    "        # true state\n",
    "        for rob in self.holding.keys():\n",
    "            ab += [Atom(\"holding\",[rob,obj]) for obj in self.holding[rob]]\n",
    "        for rob in self.rob_regions.keys():\n",
    "            ab += [Atom(\"in_rob\",[rob,self.rob_regions[rob]])]\n",
    "        for obj in self.obj_regions.keys():\n",
    "            if self.obj_regions[obj] !=\"\":\n",
    "                ab += [Atom(\"in_obj\",[obj,self.obj_regions[obj]])]\n",
    "        if self.open_door:\n",
    "            ab += [Atom(\"open\",[DOOR])]\n",
    "        \n",
    "        # next actions\n",
    "        if self.next_actions != []:\n",
    "            for next_action in self.next_actions:\n",
    "                \n",
    "                name,args = next_action.split(\"-\")\n",
    "                args=list(args.split(\"%\"))\n",
    "                \n",
    "                rob=args[0]\n",
    "                if Atom(\"is_ego\",[rob]) not in store.certified:\n",
    "                    ab += [Atom(name,args)]\n",
    "            \n",
    "        return AbstractBelief(ab)\n",
    "\n",
    "    # def vectorize(self):\n",
    "    #     return np.array([int(obj in self.holding) for obj in OBJECTS])\n",
    "      \n",
    "def get_next_actions_execute(a, b, store): # human operator : tedious, kind of works\n",
    "    \n",
    "    a_other_name,a_ego_name = a.name.split(\"*\")\n",
    "    if a_other_name == \"transfer_other\":\n",
    "        n_args=4\n",
    "    elif a_other_name == \"open_other\" or a_other_name == \"close_other\" or a_other_name == \"nothing_other\":\n",
    "        n_args = 1\n",
    "    else:\n",
    "        n_args = 3\n",
    "        \n",
    "    print(\"ego attempts action ..\")\n",
    "    print(a_ego_name)\n",
    "    print(a.args[n_args:])\n",
    "    print(\"... belief ...\")\n",
    "    b_temp=copy.deepcopy(b) \n",
    "    print(b_temp.abstract(store))\n",
    "    print(\"applicable actions...\")\n",
    "    \n",
    "    next_actions=[]\n",
    "    others = []\n",
    "    for entity in store.als_type:\n",
    "        if store.als_type[entity]==\"robot\":\n",
    "            if Atom(\"is_ego\",[entity]) not in store.certified:\n",
    "                others.append(entity)\n",
    "    \n",
    "    for rob in others: # one list of outcomes per robot\n",
    "        \n",
    "        ab = b_temp.abstract(store)\n",
    "        applicable_actions_rob=[]\n",
    "        # nothing is always applicable\n",
    "        applicable_actions_rob.append(Atom(\"nothing_action\",[rob]))\n",
    "        for reg in REGIONS:\n",
    "            for obj in OBJ_REGIONS.keys():\n",
    "                if Atom(\"holding\",[rob,obj]) in ab.items: # robot is holding an object: it can transfer or place\n",
    "                    if Atom(\"in_rob\",[rob,reg]) not in ab.items:\n",
    "                        applicable_actions_rob.append(Atom(\"transfer_action\",[rob,obj,reg]))\n",
    "                    else:\n",
    "                        if Atom(\"stable\",[obj,reg]) in store.certified:\n",
    "                            if (reg==REGIONS[0] and Atom(\"open\",[DOOR]) in ab.items) or reg!=REGIONS[0]: # region accessibility\n",
    "                                applicable_actions_rob.append(Atom(\"place_action\",[rob,obj]))\n",
    "                else: # robot is not holding an object: it can transit, open, pick, depending on where it is and where the objects are\n",
    "                    if Atom(\"in_rob\",[rob,reg]) in ab.items: # cannot move to reg\n",
    "                        if reg==REGIONS[1]:\n",
    "                            if Atom(\"open\",[DOOR]) not in ab.items: \n",
    "                                applicable_actions_rob.append(Atom(\"open_action\",[rob]))\n",
    "                            else:\n",
    "                                applicable_actions_rob.append(Atom(\"close_action\",[rob]))\n",
    "                        if Atom(\"in_obj\",[obj,reg]) in ab.items and Atom(\"in_rob\",[rob,reg]):\n",
    "                            # accessibility of obj\n",
    "                            if (reg==REGIONS[0] and Atom(\"open\",[DOOR]) in ab.items) or (reg!=REGIONS[0]):\n",
    "                                applicable_actions_rob.append(Atom(\"pick_action\",[rob,obj]))\n",
    "                    else: # can move to reg\n",
    "                        applicable_actions_rob.append(Atom(\"transit_action\",[rob,reg]))\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            for i,act in enumerate(applicable_actions_rob):\n",
    "                print(str(i)+\". \"+act.pred_name+str(act.args))\n",
    "                \n",
    "            choice = input(\"choose an action \\n\")\n",
    "            if int(choice)>=0 and int(choice)<len(applicable_actions_rob):\n",
    "                break\n",
    "            else:\n",
    "                print(\"invalid choice, enter again\")\n",
    "          \n",
    "        \n",
    "        \n",
    "        observed_action_rob = applicable_actions_rob[int(choice)]   \n",
    "        print(observed_action_rob)\n",
    "        \n",
    "        name=observed_action_rob.pred_name\n",
    "        args=observed_action_rob.args\n",
    "        \n",
    "        if name==\"transit_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]\n",
    "        elif name == \"transfer_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]+\"%\"+args[2]\n",
    "        elif name == \"pick_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]\n",
    "        elif name == \"place_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]\n",
    "        else: # open, close, nothing\n",
    "            a_other=name+\"-\"+rob\n",
    "            \n",
    "        next_actions.append(a_other)\n",
    "            \n",
    "    \n",
    "    return next_actions # for all the agents\n",
    "def get_next_actions_effects(a, b, store): # human operator : tedious, kind of works\n",
    "    \n",
    "    b_temp=copy.deepcopy(b) \n",
    "    # b_temp=b_temp.update(a,None,None)\n",
    "    \n",
    "    next_actions = []\n",
    "    \n",
    "    others = []\n",
    "    \n",
    "    for entity in store.als_type:\n",
    "        if store.als_type[entity]==\"robot\":\n",
    "            if Atom(\"is_ego\",[entity]) not in store.certified:\n",
    "                others.append(entity)\n",
    "    \n",
    "    for rob in others: # one list of outcomes per robot\n",
    "        \n",
    "        ab = b_temp.abstract(store)\n",
    "        applicable_actions_rob=[]\n",
    "        # nothing is always applicable\n",
    "        applicable_actions_rob.append(Atom(\"nothing_action\",[rob]))\n",
    "        \n",
    "        observed_action_rob = \"\"\n",
    "\n",
    "        for reg in REGIONS:\n",
    "            for obj in OBJ_REGIONS.keys():\n",
    "                if Atom(\"holding\",[rob,obj]) in ab.items: # robot is holding an object: it can transfer or place\n",
    "                    if Atom(\"in_rob\",[rob,reg]) not in ab.items:\n",
    "                        applicable_actions_rob.append(Atom(\"transfer_action\",[rob,obj,reg]))\n",
    "                    else:\n",
    "                        if Atom(\"stable\",[obj,reg]) in store.certified:\n",
    "                            if (reg==REGIONS[0] and Atom(\"open\",[DOOR]) in ab.items) or reg!=REGIONS[0]: # region accessibility\n",
    "                                applicable_actions_rob.append(Atom(\"place_action\",[rob,obj]))\n",
    "                                observed_action_rob=Atom(\"place_action\",[rob,obj])\n",
    "                else: # robot is not holding an object: it can transit, open, pick, depending on where it is and where the objects are\n",
    "                    if Atom(\"in_rob\",[rob,reg]) in ab.items: # cannot move to reg\n",
    "                        if reg==REGIONS[1]:\n",
    "                            if Atom(\"open\",[DOOR]) not in ab.items: # door\n",
    "                                applicable_actions_rob.append(Atom(\"open_action\",[rob]))\n",
    "                                observed_action_rob=Atom(\"open_action\",[rob])\n",
    "                                break\n",
    "                            else:\n",
    "                                applicable_actions_rob.append(Atom(\"close_action\",[rob]))\n",
    "                                observed_action_rob=Atom(\"close_action\",[rob])\n",
    "                                break\n",
    "                        if Atom(\"in_obj\",[obj,reg]) in ab.items and Atom(\"in_rob\",[rob,reg]):\n",
    "                            # accessibility of obj\n",
    "                            if (reg==REGIONS[0] and Atom(\"open\",[DOOR]) in ab.items) or (reg!=REGIONS[0]):\n",
    "                                applicable_actions_rob.append(Atom(\"pick_action\",[rob,obj]))\n",
    "                                observed_action_rob=Atom(\"pick_action\",[rob,obj])\n",
    "                                break\n",
    "                    else: # can move to reg\n",
    "                        applicable_actions_rob.append(Atom(\"transit_action\",[rob,reg]))\n",
    "\n",
    "        # simulation: if pick, place, open, close are applicable, the other agent tends to perform that action\n",
    "        if observed_action_rob == \"\":\n",
    "            observed_action_rob = random.choice(applicable_actions_rob)\n",
    "        else: # 70% of time \"goal directed\" actions, 30% of the time random\n",
    "            if random.random()<0.3:\n",
    "                observed_action_rob = random.choice(applicable_actions_rob)\n",
    "                \n",
    "        #observed_action_rob = Atom(\"nothing_action\",[rob]) # INACTIVE OTHER AGENT!!!\n",
    "        \n",
    "        name=observed_action_rob.pred_name\n",
    "        args=observed_action_rob.args\n",
    "        \n",
    "        if name==\"transit_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]\n",
    "        elif name == \"transfer_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]+\"%\"+args[2]\n",
    "        elif name == \"pick_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]\n",
    "        elif name == \"place_action\":\n",
    "            a_other=name+\"-\"+rob+\"%\"+args[1]\n",
    "        else: # open, close, nothing\n",
    "            a_other=name+\"-\"+rob\n",
    "            \n",
    "        next_actions.append(a_other)\n",
    "    \n",
    "    \n",
    "    return next_actions # for all the agents\n",
    "\n",
    "def non_deterministic_ego_execute_fn(a, b, s, store):\n",
    "    \n",
    "    a_other_name,a_ego_name = a.name.split(\"*\")\n",
    "    \n",
    "    if a_other_name == \"transfer_other\":\n",
    "        n_args = 4\n",
    "    elif a_other_name == \"open_other\" or a_other_name == \"close_other\" or a_other_name == \"nothing_other\":\n",
    "        n_args = 1\n",
    "    else:\n",
    "        n_args = 3\n",
    "    \n",
    "    args_ego = a.args[n_args:]\n",
    "    \n",
    "    \n",
    "    # remove ego's previous action\n",
    "    for na in s.next_actions: \n",
    "        name,args = na.split(\"-\")\n",
    "        args=args.split(\"%\")\n",
    "        if args[0] == args_ego[0]:\n",
    "            s.next_actions.remove(na)\n",
    "    \n",
    "    if a_ego_name == \"transit_ego\" or a_ego_name == \"transfer_ego\":\n",
    "        \n",
    "        if random.random()<0.9: # 90% success\n",
    "            s.rob_regions[args_ego[0]] = args_ego[2]\n",
    "            \n",
    "        next_action = a_ego_name[:-3]+\"action\"+\"-\"+args_ego[0]+\"%\"+args_ego[2]\n",
    "        \n",
    "        # additional argument \n",
    "        if a_ego_name == \"transfer_ego\":\n",
    "            next_action = next_action + \"%\" + args_ego[3]\n",
    "            \n",
    "    elif a_ego_name == \"pick_ego\":\n",
    "        \n",
    "        if random.random()<0.9: # 90% success\n",
    "            s.holding[args_ego[0]] = [args_ego[1]]\n",
    "            s.obj_regions[args_ego[1]] = \"\"\n",
    "            \n",
    "        next_action = a_ego_name[:-3]+\"action\"+\"-\"+args_ego[0]+\"%\"+args_ego[1]\n",
    "        \n",
    "    elif a_ego_name == \"place_ego\":\n",
    "        \n",
    "        if random.random()<0.9: # 90% success\n",
    "            s.holding[args_ego[0]] = []\n",
    "            s.obj_regions[args_ego[1]] = args_ego[2]\n",
    "            \n",
    "        next_action = a_ego_name[:-3]+\"action\"+\"-\"+args_ego[0]+\"%\"+args_ego[1]\n",
    "        \n",
    "    elif a_ego_name == \"open_ego\":\n",
    "        \n",
    "        if random.random()<0.9: # 90% success\n",
    "            s.open_door = True\n",
    "            \n",
    "        next_action = a_ego_name[:-3]+\"action\"+\"-\"+args_ego[0]\n",
    "        \n",
    "    elif a_ego_name == \"close_ego\":\n",
    "        \n",
    "        if random.random()<0.9: # 90% success\n",
    "            s.open_door = False\n",
    "            \n",
    "        next_action = a_ego_name[:-3]+\"action\"+\"-\"+args_ego[0]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        next_action = a_ego_name[:-3]+\"action\"+\"-\"+args_ego[0]\n",
    "        \n",
    "        \n",
    "    # add ego's next action for the other agent     \n",
    "    s.next_actions.append(next_action)   \n",
    "    \n",
    "    next_actions = s.next_actions.copy() \n",
    "    \n",
    "    for na in next_actions: # replace other agents' previous action with noop (temporary, till observation is received)\n",
    "        name,args = na.split(\"-\")\n",
    "        args=args.split(\"%\")\n",
    "        if args[0] != args_ego[0]:\n",
    "            next_actions.remove(na)\n",
    "            next_actions.append(\"nothing_action-\"+args[0])\n",
    "    \n",
    "    return s, EnvObservation(next_actions=next_actions)\n",
    "def non_deterministic_ego_effects_fn(a, b, store):\n",
    "    a_other_name,a_ego_name = a.name.split(\"*\")\n",
    "    \n",
    "    if a_other_name == \"transfer_other\":\n",
    "        n_args = 4\n",
    "    elif a_other_name == \"open_other\" or a_other_name == \"close_other\" or a_other_name == \"nothing_other\":\n",
    "        n_args = 1\n",
    "    else:\n",
    "        n_args = 3\n",
    "    \n",
    "    args_ego = a.args[n_args:]\n",
    "    \n",
    "    next_actions = get_next_actions_effects(a, b, store)\n",
    "    o = EnvObservation(next_actions=next_actions)\n",
    "    o.rob_regions = b.rob_regions.copy()\n",
    "    o.holding = b.holding.copy()\n",
    "    o.obj_regions = b.obj_regions.copy()\n",
    "    o.open_door = b.open_door\n",
    "    \n",
    "    if a_ego_name == \"transit_ego\" or a_ego_name == \"transfer_ego\":\n",
    "        if random.random()<0.9: # 90% success\n",
    "            o.rob_regions[args_ego[0]] = args_ego[2]\n",
    "    elif a_ego_name == \"pick_ego\":\n",
    "        if random.random()<0.9: # 90% success\n",
    "            o.holding[args_ego[0]] = [args_ego[1]]\n",
    "            o.obj_regions[args_ego[1]] = \"\"\n",
    "    elif a_ego_name == \"place_ego\":\n",
    "        if random.random()<0.9: # 90% success\n",
    "            o.holding[args_ego[0]] = []\n",
    "            o.obj_regions[args_ego[1]] = args_ego[2]\n",
    "    elif a_ego_name == \"open_ego\":\n",
    "        if random.random()<0.9: # 90% success\n",
    "            o.open_door = True\n",
    "    elif a_ego_name == \"close_ego\":\n",
    "        if random.random()<0.9: # 90% success\n",
    "            o.open_door = False\n",
    "    \n",
    "    new_belief=b.update(a,o,store)\n",
    "    \n",
    "    return AbstractBeliefSet.from_beliefs([new_belief], store)\n",
    "\n",
    "# other agents actions\n",
    "def transit_transfer_other_execute_fn(a, b, s, store):\n",
    "    \n",
    "    rob_regions = b.rob_regions.copy()    \n",
    "    \n",
    "    rob_regions[a.args[0]] = s.rob_regions[a.args[0]]\n",
    "    \n",
    "    return s, EnvObservation(rob_regions=rob_regions)\n",
    "def transit_transfer_other_effects_fn(a, b, store):\n",
    "    p = [] # sample probabilities for weighting\n",
    "    for reg in REGIONS:\n",
    "        if reg == a.args[2]:\n",
    "            p.append(0.7) # random outcome\n",
    "            # p.append(1.0) # deterministic outcome\n",
    "        else:\n",
    "            p.append(0.15) # random outcome\n",
    "            # p.append(0.0) # deterministic outcome\n",
    "    rob_regions = b.rob_regions.copy()    \n",
    "    rob_regions[a.args[0]] = random.choice(REGIONS)#np.random.choice(np.array(ROB_REGIONS),p=np.array(p)) # weighted probabilities\n",
    "    \n",
    "    return rob_regions\n",
    "    \n",
    "def pick_other_execute_fn(a, b, s, store):        \n",
    "    \n",
    "    obj_regions = b.obj_regions.copy()\n",
    "    holding = b.holding.copy()\n",
    "            \n",
    "    if s.obj_regions[a.args[1]] == \"\" and s.holding[a.args[0]] == [a.args[1]]: # picked\n",
    "        print(\"picked\")\n",
    "        obj_regions[a.args[1]] = \"\"\n",
    "        holding[a.args[0]] = [a.args[1]]\n",
    "    else:\n",
    "        print(\"not picked\")\n",
    "    \n",
    "    return s, EnvObservation(obj_regions=obj_regions,holding=holding)\n",
    "def pick_other_effects_fn(a, b, store):\n",
    "    \n",
    "    obj_regions = b.obj_regions.copy()\n",
    "    holding = b.holding.copy()\n",
    "    \n",
    "    # if random.random()<=1.0: # deterministic outcome\n",
    "    if random.random()<=0.9: # picked # tweak this number to have a higher probability of pick\n",
    "        obj_regions[a.args[1]] = \"\"\n",
    "        holding[a.args[0]] = [a.args[1]]\n",
    "    \n",
    "    return obj_regions,holding\n",
    "    \n",
    "\n",
    "def place_other_execute_fn(a, b, s, store):\n",
    "    \n",
    "    obj_regions = b.obj_regions.copy()\n",
    "    holding = b.holding.copy()\n",
    "    \n",
    "    if s.obj_regions[a.args[1]] == a.args[2] and s.holding[a.args[0]] == []: # placed\n",
    "        print(\"placed\")\n",
    "        obj_regions[a.args[1]] = a.args[2]\n",
    "        holding[a.args[0]] = []\n",
    "    else:\n",
    "        print(\"not placed\")\n",
    "    \n",
    "    return s, EnvObservation(obj_regions=obj_regions,holding=holding)\n",
    "def place_other_effects_fn(a, b, store):\n",
    "    \n",
    "    obj_regions = b.obj_regions.copy()\n",
    "    holding = b.holding.copy()\n",
    "    \n",
    "    # if random.random()<=1.0: # deterministic outcome\n",
    "    if random.random()<=0.9: # placed # tweak this number to have a higher probability of place\n",
    "        obj_regions[a.args[1]] = a.args[2]\n",
    "        holding[a.args[0]] = []\n",
    "    \n",
    "    return obj_regions,holding\n",
    "    # o = EnvObservation(obj_regions=obj_regions,holding=holding)\n",
    "    # new_belief = b.update(a, o, store)\n",
    "    # return AbstractBeliefSet.from_beliefs([new_belief], store)\n",
    "\n",
    "def open_other_execute_fn(a, b, s, store):\n",
    "    \n",
    "    open_door = b.open_door\n",
    "    \n",
    "    if s.open_door: # opened\n",
    "        print(\"opened\")\n",
    "        open_door = True\n",
    "    else:\n",
    "        print(\"not opened\")\n",
    "    \n",
    "    return s, EnvObservation(open_door=open_door)\n",
    "def open_other_effects_fn(a, b, store):\n",
    "    \n",
    "    open_door = b.open_door\n",
    "    \n",
    "    # if random.random()<=1.0: # deterministic outcome\n",
    "    if random.random()<=0.8:\n",
    "        open_door = True\n",
    "        \n",
    "    return open_door    \n",
    "    # o = EnvObservation(open_door=open_door)\n",
    "    # new_belief = b.update(a, o, store)\n",
    "    # return AbstractBeliefSet.from_beliefs([new_belief], store)\n",
    "\n",
    "def close_other_execute_fn(a, b, s, store):\n",
    "\n",
    "    open_door = b.open_door\n",
    "    \n",
    "    if not s.open_door: # closed\n",
    "        print(\"closed\")\n",
    "        open_door = False\n",
    "    else:\n",
    "        print(\"not closed\")\n",
    "    \n",
    "    return s, EnvObservation(open_door=open_door)\n",
    "def close_other_effects_fn(a, b, store):\n",
    "    \n",
    "    open_door = b.open_door\n",
    "    \n",
    "    # if random.random()<=1.0: # deterministic outcome\n",
    "    if random.random()<=0.8:\n",
    "        open_door = False\n",
    "        \n",
    "    return open_door\n",
    "    # o = EnvObservation(open_door=open_door)\n",
    "    # new_belief = b.update(a, o, store)\n",
    "    # return AbstractBeliefSet.from_beliefs([new_belief], store)    \n",
    "\n",
    "\n",
    "# joint actions\n",
    "def joint_execute_fn(a, b, s, store):\n",
    "    \n",
    "    holding = b.holding.copy()\n",
    "    open_door = b.open_door\n",
    "    rob_regions = b.rob_regions.copy()\n",
    "    obj_regions = b.obj_regions.copy()\n",
    "    next_actions = b.next_actions.copy()\n",
    "    \n",
    "    a_other_name, a_ego_name = a.name.split(\"*\")\n",
    "\n",
    "    # special cases\n",
    "    # remember: next actions!!\n",
    "    # case 1: place, pick\n",
    "    if a_other_name == \"place_other\" and a_ego_name == \"pick_ego\": \n",
    "        print(\"special case\")\n",
    "        print(a.name)\n",
    "        s,obs = place_other_execute_fn(a, b, s, store)\n",
    "        obj_regions = s.obj_regions\n",
    "        if obj_regions[a.args[1]] == a.args[2]: # other agent placed the object\n",
    "            if random.random()<0.9: # 90% success\n",
    "                holding[a.args[3]] = [a.args[1]]\n",
    "                obj_regions[a.args[1]] = \"\"\n",
    "                # update state\n",
    "                s.holding[a.args[3]] = [a.args[1]]\n",
    "                s.obj_regions[a.args[1]] = \"\"\n",
    "            \n",
    "    # case 2: open, pick\n",
    "    elif a_other_name == \"open_other\" and a_ego_name == \"pick_ego\":\n",
    "        print(\"special case\")\n",
    "        print(a.name)\n",
    "        s,obs = open_other_execute_fn(a, b, s, store)\n",
    "        open_door = s.open_door\n",
    "        if (a.args[3] == REGIONS[0] and open_door) or a.args[3] != REGIONS[0]: # in mug and door open or not in mug!\n",
    "            if random.random()<0.9: # 90% success\n",
    "                holding[a.args[1]] = [a.args[2]]\n",
    "                obj_regions[a.args[2]] = \"\"\n",
    "                # update state\n",
    "                s.holding[a.args[1]] = [a.args[2]]\n",
    "                s.obj_regions[a.args[2]] = \"\"\n",
    "        \n",
    "            \n",
    "    # case 3: open, place\n",
    "    elif a_other_name == \"open_other\" and a_ego_name == \"place_ego\":\n",
    "        print(\"special case\")\n",
    "        print(a.name)\n",
    "        s,obs = open_other_execute_fn(a, b, s, store)\n",
    "        open_door = s.open_door\n",
    "        if (a.args[3] == REGIONS[0] and open_door) or a.args[3] != REGIONS[0]: # in mug and door open or not in mug!\n",
    "            if random.random()<0.9: # 90% success\n",
    "                holding[a.args[1]] = []\n",
    "                obj_regions[a.args[2]] = a.args[3]\n",
    "                # update state\n",
    "                s.holding[a.args[1]] = []\n",
    "                s.obj_regions[a.args[2]] = a.args[3]\n",
    "        \n",
    "        \n",
    "    # case 4: open, close\n",
    "    elif a_other_name == \"open_other\" and a_ego_name == \"close_ego\":\n",
    "        print(\"special case\")\n",
    "        print(a.name)\n",
    "        s,obs = open_other_execute_fn(a, b, s, store)\n",
    "        open_door = s.open_door\n",
    "        if open_door and random.random()<0.9: # 90% success\n",
    "            open_door = False\n",
    "            # update state\n",
    "            s.open_door = open_door\n",
    "            \n",
    "    # case 5: close, pick\n",
    "    # case 6: close, place\n",
    "    elif a_other_name == \"close_other\" and (a_ego_name == \"pick_ego\" or a_ego_name == \"place_ego\"):\n",
    "        print(\"special case\")\n",
    "        print(a.name)\n",
    "        s,obs = close_other_execute_fn(a, b, s, store)\n",
    "        open_door = obs.open_door\n",
    "        \n",
    "        \n",
    "    # case 7: close, open\n",
    "    elif a_other_name == \"close_other\" and a_ego_name == \"open_ego\":\n",
    "        print(\"special case\")\n",
    "        print(a.name)\n",
    "        s,obs = close_other_execute_fn(a, b, s, store)\n",
    "        open_door = s.open_door\n",
    "        if not open_door and random.random()<0.9: # 90% success\n",
    "            open_door = True\n",
    "            # update state\n",
    "            s.open_door = open_door\n",
    "        \n",
    "    else: # rest\n",
    "        \n",
    "        # other: non-deterministic, ego: deterministic\n",
    "        \n",
    "        if a_other_name == \"transit_other\" or a_other_name == \"transfer_other\":\n",
    "            \n",
    "            s,obs = transit_transfer_other_execute_fn(a, b, s, store)\n",
    "            rob_regions[a.args[0]] = s.rob_regions[a.args[0]]\n",
    "             \n",
    "        elif a_other_name == \"open_other\":\n",
    "            \n",
    "            s,obs = open_other_execute_fn(a, b, s, store)\n",
    "            open_door = s.open_door\n",
    "            \n",
    "            \n",
    "        elif a_other_name == \"close_other\":\n",
    "            \n",
    "            s,obs = close_other_execute_fn(a, b, s, store)\n",
    "            open_door = s.open_door\n",
    "            \n",
    "            \n",
    "        elif a_other_name == \"pick_other\":\n",
    "            \n",
    "            s,obs = pick_other_execute_fn(a, b, s, store)\n",
    "            obj_regions[a.args[1]] = s.obj_regions[a.args[1]]\n",
    "            holding[a.args[0]] = s.holding[a.args[0]]\n",
    "            \n",
    "            \n",
    "        elif a_other_name == \"place_other\":\n",
    "            \n",
    "            s,obs = place_other_execute_fn(a, b, s, store)\n",
    "            obj_regions[a.args[1]] = s.obj_regions[a.args[1]]\n",
    "            holding[a.args[0]] = s.holding[a.args[0]]\n",
    "            \n",
    "     \n",
    "           \n",
    "    #  next actions\n",
    "    \n",
    "    b_temp = copy.deepcopy(b)\n",
    "    o = EnvObservation(holding=holding,open_door=open_door,rob_regions=rob_regions,obj_regions=obj_regions)\n",
    "    b_temp = b_temp.update(a,o,store)    \n",
    "    # s is updated by non-deterministic ego execution    \n",
    "    s,obs = non_deterministic_ego_execute_fn(a, b_temp, s, store) # next actions updated with next_actions of ego agent, not other agent!\n",
    "    next_actions = obs.next_actions\n",
    "        \n",
    "    return s, EnvObservation(holding=s.holding,open_door=s.open_door,rob_regions=s.rob_regions,obj_regions=s.obj_regions,next_actions=next_actions)  \n",
    "def joint_effects_fn(a, b, store):\n",
    "    \n",
    "    holding = b.holding.copy()\n",
    "    open_door = b.open_door\n",
    "    rob_regions = b.rob_regions.copy()\n",
    "    obj_regions = b.obj_regions.copy()\n",
    "    next_actions = b.next_actions.copy()\n",
    "    \n",
    "    a_other_name,a_ego_name = a.name.split(\"*\")\n",
    "    \n",
    "    if a_other_name == \"transfer_other\":\n",
    "        n_args = 4\n",
    "    elif a_other_name == \"open_other\" or a_other_name == \"close_other\" or a_other_name == \"nothing_other\":\n",
    "        n_args = 1\n",
    "    else:\n",
    "        n_args = 3\n",
    "    \n",
    "    args_ego = a.args[n_args:]\n",
    "    \n",
    "    \n",
    "    # special cases\n",
    "    # remember: next actions!!\n",
    "    # case 1: place, pick\n",
    "    if a_other_name == \"place_other\" and a_ego_name == \"pick_ego\": \n",
    "        \n",
    "        obj_regions,holding = place_other_effects_fn(a, b, store)\n",
    "        \n",
    "        if obj_regions[a.args[1]] == a.args[2]: # other agent placed the object\n",
    "            if random.random()<0.9: # ego:non-deterministic\n",
    "                holding[a.args[3]] = [a.args[1]]\n",
    "                obj_regions[a.args[1]] = \"\"\n",
    "        \n",
    "            \n",
    "    # case 2: open, pick\n",
    "    elif a_other_name == \"open_other\" and a_ego_name == \"pick_ego\":\n",
    "        \n",
    "        open_door = open_other_effects_fn(a, b, store)\n",
    "        \n",
    "        if (a.args[3] == REGIONS[0] and open_door) or a.args[3] != REGIONS[0]: # in mug and door open or not in mug!\n",
    "            if random.random()<0.9:\n",
    "                holding[a.args[1]] = [a.args[2]]\n",
    "                obj_regions[a.args[2]] = \"\"\n",
    "        \n",
    "            \n",
    "    # case 3: open, place\n",
    "    elif a_other_name == \"open_other\" and a_ego_name == \"place_ego\":\n",
    "        \n",
    "        open_door = open_other_effects_fn(a, b, store)\n",
    "        \n",
    "        if (a.args[3] == REGIONS[0] and open_door) or a.args[3] != REGIONS[0]: # in mug and door open or not in mug!\n",
    "            if random.random()<0.9:\n",
    "                holding[a.args[1]] = []\n",
    "                obj_regions[a.args[2]] = a.args[3]\n",
    "        \n",
    "            \n",
    "    # case 4: open, close\n",
    "    elif a_other_name == \"open_other\" and a_ego_name == \"close_ego\":\n",
    "        \n",
    "        if random.random()<0.9:\n",
    "            open_door = False\n",
    "        \n",
    "        \n",
    "    # case 5: close, pick\n",
    "    # case 6: close, place\n",
    "    elif a_other_name == \"close_other\" and (a_ego_name == \"pick_ego\" or a_ego_name == \"place_ego\"):\n",
    "        \n",
    "        open_door = close_other_effects_fn(a, b, store)\n",
    "        \n",
    "        if a_ego_name == \"pick_ego\":\n",
    "            if random.random()<0.9:\n",
    "                holding[a.args[1]] = [a.args[2]]\n",
    "                obj_regions[a.args[2]] = \"\"\n",
    "        else:\n",
    "            if random.random()<0.9:\n",
    "                holding[a.args[1]] = []\n",
    "                obj_regions[a.args[2]] = a.args[3]\n",
    "        \n",
    "    # case 7: close, open\n",
    "    elif a_other_name == \"close_other\" and a_ego_name == \"open_ego\":\n",
    "        \n",
    "        if random.random()<0.9:\n",
    "            open_door = True\n",
    "        \n",
    "    else: # rest\n",
    "        # other: non-deterministic\n",
    "        \n",
    "        if a_other_name == \"transit_other\" or a_other_name == \"transfer_other\":\n",
    "            \n",
    "            rob_regions = transit_transfer_other_effects_fn(a, b, store)\n",
    "            \n",
    "            \n",
    "        elif a_other_name == \"open_other\":\n",
    "            \n",
    "            open_door = open_other_effects_fn(a, b, store)\n",
    "            \n",
    "        elif a_other_name == \"close_other\":\n",
    "            \n",
    "            open_door = close_other_effects_fn(a, b, store)\n",
    "            \n",
    "        elif a_other_name == \"pick_other\":\n",
    "            \n",
    "            obj_regions,holding = pick_other_effects_fn(a, b, store)\n",
    "            \n",
    "            \n",
    "        elif a_other_name == \"place_other\":\n",
    "            \n",
    "            obj_regions,holding = place_other_effects_fn(a, b, store)\n",
    "            \n",
    "        # ego: non-deterministic\n",
    "        \n",
    "        if a_ego_name == \"transit_ego\" or a_ego_name == \"transfer_ego\":\n",
    "            if random.random()<0.9:\n",
    "                rob_regions[args_ego[0]] = args_ego[2]\n",
    "        elif a_ego_name == \"pick_ego\":\n",
    "            if random.random()<0.9:\n",
    "                holding[args_ego[0]] = [args_ego[1]]\n",
    "                obj_regions[args_ego[1]] = \"\"\n",
    "        elif a_ego_name == \"place_ego\":\n",
    "            if random.random()<0.9:\n",
    "                holding[args_ego[0]] = []\n",
    "                obj_regions[args_ego[1]] = args_ego[2]\n",
    "        elif a_ego_name == \"open_ego\":\n",
    "            if random.random()<0.9:\n",
    "                open_door = True\n",
    "        elif a_ego_name == \"close_ego\":\n",
    "            if random.random()<0.9:\n",
    "                open_door = False\n",
    "    \n",
    "    # resulting state\n",
    "    b_temp = copy.deepcopy(b)\n",
    "    obs = EnvObservation(holding=holding,open_door=open_door,rob_regions=rob_regions,obj_regions=obj_regions)\n",
    "    b_temp = b_temp.update(a,obs,store)   \n",
    "    next_actions = get_next_actions_effects(a, b_temp, store)\n",
    "    \n",
    "    o = EnvObservation(holding=holding,open_door=open_door,rob_regions=rob_regions,obj_regions=obj_regions,next_actions=next_actions)    \n",
    "    new_belief=b.update(a,o,store)\n",
    "    return AbstractBeliefSet.from_beliefs([new_belief], store)        \n",
    "            \n",
    "\n",
    "# rest of the ego-actions have deterministic effects! \n",
    "\n",
    "# Set up environment dynamics\n",
    "class ToyDiscrete(TampuraEnv):\n",
    "    \n",
    "    def initialize(self,ego=f\"{ROB}1\",s=EnvState()):\n",
    "        \n",
    "        self.ego=ego\n",
    "        \n",
    "        store = AliasStore()\n",
    "        \n",
    "        for rob in ROBOTS:\n",
    "            \n",
    "            store.set(rob, rob, \"robot\")\n",
    "        # store.set(ego,ego,\"robot\")\n",
    "            \n",
    "        for region in REGIONS:\n",
    "            store.set(region, region, \"region\")\n",
    "        \n",
    "        store.set(MUG, MUG, \"physical\")\n",
    "        store.set(DOOR, DOOR, \"door\")\n",
    "        \n",
    "        store.certified.append(Atom(\"stable\",[MUG,REGIONS[0]]))\n",
    "        store.certified.append(Atom(\"stable\",[MUG,REGIONS[2]]))\n",
    "        \n",
    "        store.certified.append(Atom(\"is_ego\",[ego]))\n",
    "\n",
    "        holding = s.holding\n",
    "        open_door = s.open_door\n",
    "        rob_regions = s.rob_regions\n",
    "        obj_regions = s.obj_regions\n",
    "        next_actions = s.next_actions\n",
    "\n",
    "        b = EnvBelief(holding=holding,open_door=open_door,rob_regions=rob_regions,obj_regions=obj_regions,\n",
    "                      next_actions=next_actions)\n",
    "\n",
    "        return b, store\n",
    "\n",
    "    def get_problem_spec(self) -> ProblemSpec:\n",
    "        \n",
    "        actions_other = ACTION_NAMES\n",
    "        \n",
    "        others=[]\n",
    "        for rob in ROBOTS:\n",
    "            if rob != self.ego:\n",
    "                others.append(rob)\n",
    "\n",
    "        predicates = [\n",
    "            Predicate(\"is_ego\",[\"robot\"]),\n",
    "            Predicate(\"holding\", [\"robot\",\"physical\"]),\n",
    "            Predicate(\"stable\",[\"physical\",\"region\"]),\n",
    "            Predicate(\"in_rob\",[\"robot\",\"region\"]),\n",
    "            Predicate(\"in_obj\",[\"physical\",\"region\"]),\n",
    "            Predicate(\"open\",[\"door\"]),\n",
    "        ] \n",
    "        action_predicates = [Predicate(\"transit_action\",[\"robot\",\"region\"]),Predicate(\"transfer_action\",[\"robot\",\"physical\",\"region\"]),Predicate(\"pick_action\",[\"robot\",\"physical\"]),\n",
    "                             Predicate(\"place_action\",[\"robot\",\"physical\"]),Predicate(\"open_action\",[\"robot\"]),Predicate(\"close_action\",[\"robot\"]),Predicate(\"nothing_action\",[\"robot\"])]\n",
    "        \n",
    "        predicates += action_predicates\n",
    "        \n",
    "        possible_outcomes = [[Atom(\"transit_action\",[rob,reg]) for reg in REGIONS]+[Atom(\"transfer_action\",[rob,obj,reg]) for obj in OBJ_REGIONS.keys() for reg in REGIONS] +\n",
    "                            [Atom(\"pick_action\",[rob,obj]) for obj in OBJ_REGIONS.keys()] + [Atom(\"place_action\",[rob,obj])for obj in OBJ_REGIONS.keys()] +\n",
    "                            [Atom(\"open_action\",[rob]),Atom(\"close_action\",[rob]),Atom(\"nothing_action\",[rob])] for rob in others]\n",
    "        \n",
    "        possible_outcomes_pick_place = [[Atom(\"transit_action\",[rob,reg]) for reg in REGIONS]+[Atom(\"transfer_action\",[rob,obj,reg]) for obj in OBJ_REGIONS.keys() for reg in REGIONS] +\n",
    "                                        [Atom(\"pick_action\",[rob,obj]) for obj in OBJ_REGIONS.keys()] + [Atom(\"place_action\",[rob,obj])for obj in OBJ_REGIONS.keys()] +\n",
    "                                        [Atom(\"nothing_action\",[rob])] for rob in others]\n",
    "        \n",
    "        possible_outcomes_open_close = [[Atom(\"transit_action\",[rob,reg]) for reg in REGIONS]+\n",
    "                                        [Atom(\"open_action\",[rob]),Atom(\"close_action\",[rob]),Atom(\"nothing_action\",[rob])] for rob in others]\n",
    "        \n",
    "        possible_outcomes_transit = [[Atom(\"transit_action\",[rob,reg]) for reg in REGIONS]+\n",
    "                                     [Atom(\"pick_action\",[rob,obj]) for obj in OBJ_REGIONS.keys()] +\n",
    "                                     [Atom(\"open_action\",[rob]),Atom(\"close_action\",[rob]),Atom(\"nothing_action\",[rob])] for rob in others]\n",
    "        \n",
    "        possible_outcomes_transfer = [[Atom(\"transfer_action\",[rob,obj,reg]) for obj in OBJ_REGIONS.keys() for reg in REGIONS] +\n",
    "                                      [Atom(\"place_action\",[rob,obj])for obj in OBJ_REGIONS.keys()] +\n",
    "                                      [Atom(\"nothing_action\",[rob])] for rob in others]\n",
    "        \n",
    "        \n",
    "        # modify preconditions, effects and execute functions for observation\n",
    "        action_schemas_ego = [\n",
    "            \n",
    "            # ego-agent\n",
    "            ActionSchema(\n",
    "                name=\"pick_ego\",\n",
    "                inputs=[\"?rob1\",\"?obj1\",\"?reg1\"],\n",
    "                input_types=[\"robot\",\"physical\",\"region\"],\n",
    "                preconditions=[Atom(\"is_ego\",[\"?rob1\"]), # is the ego agent\n",
    "                               Or([Not(Atom(\"in_rob\",[\"?rob1\",REGIONS[0]])),And([Atom(\"in_rob\",[\"?rob1\",REGIONS[0]]),Atom(\"open\",[DOOR])])]), # TODO: modify!! accesibility of mug: derived predicate\n",
    "                               Atom(\"in_obj\",[\"?obj1\",\"?reg1\"]), # object is in region from where pick is attempted\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]), # robot is in region from where pick is attempted\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"])), # robot hand is free\n",
    "                               ],\n",
    "                verify_effects=[OneOf([Atom(\"holding\",[\"?rob1\",\"?obj1\"]),Atom(\"in_obj\",[\"?obj1\",\"?reg1\"])])], # deterministic\n",
    "\n",
    "            ),\n",
    "            \n",
    "            \n",
    "            ActionSchema(\n",
    "                name=\"place_ego\",\n",
    "                inputs=[\"?rob1\",\"?obj1\",\"?reg1\"],\n",
    "                input_types=[\"robot\",\"physical\",\"region\"],\n",
    "                preconditions=[Atom(\"is_ego\",[\"?rob1\"]), # is the ego agent\n",
    "                               Or([Not(Atom(\"in_rob\",[\"?rob1\",REGIONS[0]])),And([Atom(\"in_rob\",[\"?rob1\",REGIONS[0]]),Atom(\"open\",[DOOR])])]), # TODO: modify!! accessibility of region\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]), # robot is in region where place is attempted\n",
    "                               Atom(\"holding\",[\"?rob1\",\"?obj1\"]), # robot is holding the object that is to be placed \n",
    "                               Atom(\"stable\",[\"?obj1\",\"?reg1\"]), # region where place is attempted is stable\n",
    "                               ],\n",
    "                verify_effects=[OneOf([Atom(\"holding\",[\"?rob1\",\"?obj1\"]),Atom(\"in_obj\",[\"?obj1\",\"?reg1\"])])], # deterministic \n",
    "            ),\n",
    "            \n",
    "\n",
    "            ActionSchema(\n",
    "                name=\"transit_ego\",\n",
    "                inputs=[\"?rob1\",\"?reg1\",\"?reg2\"],\n",
    "                input_types=[\"robot\",\"region\",\"region\"],\n",
    "                preconditions=[Atom(\"is_ego\",[\"?rob1\"]), # is the ego agent\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]),\n",
    "                               Not(Atom(\"in_rob\",[\"?rob1\",\"?reg2\"])),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"])), # robot hand is free\n",
    "                               ],\n",
    "                verify_effects=[OneOf([Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]),Atom(\"in_rob\",[\"?rob1\",\"?reg2\"])])],\n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"transfer_ego\",\n",
    "                inputs=[\"?rob1\",\"?reg1\",\"?reg2\",\"?obj1\"],\n",
    "                input_types=[\"robot\",\"region\",\"region\",\"physical\"],\n",
    "                preconditions=[Atom(\"is_ego\",[\"?rob1\"]), # is the ego agent\n",
    "                               Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]),\n",
    "                               Not(Atom(\"in_rob\",[\"?rob1\",\"?reg2\"])),\n",
    "                               Atom(\"holding\",[\"?rob1\",\"?obj1\"])],\n",
    "                verify_effects=[OneOf([Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]),Atom(\"in_rob\",[\"?rob1\",\"?reg2\"])])],\n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"open_ego\",\n",
    "                inputs=[\"?rob1\"],\n",
    "                input_types=[\"robot\"],\n",
    "                preconditions=[Atom(\"is_ego\",[\"?rob1\"]), # is the ego agent\n",
    "                               Not(Atom(\"open\",[DOOR])),\n",
    "                               Atom(\"in_rob\",[\"?rob1\",REGIONS[1]]),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"]))],\n",
    "                verify_effects=[Atom(\"open\",[DOOR])],\n",
    "                \n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"close_ego\",\n",
    "                inputs=[\"?rob1\"],\n",
    "                input_types=[\"robot\"],\n",
    "                preconditions=[Atom(\"is_ego\",[\"?rob1\"]), # is the ego agent\n",
    "                               Atom(\"open\",[DOOR]),\n",
    "                               Atom(\"in_rob\",[\"?rob1\",REGIONS[1]]),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"]))],\n",
    "                verify_effects=[Not(Atom(\"open\",[DOOR]))],\n",
    "        \n",
    "            ),\n",
    "            \n",
    "            ActionSchema(\n",
    "                name=\"nothing_ego\",\n",
    "                inputs=[\"?rob1\"],\n",
    "                input_types=[\"robot\"],\n",
    "                preconditions=[Atom(\"is_ego\",[\"?rob1\"])],\n",
    "                effects=[],\n",
    "            ),\n",
    "        ]\n",
    "        \n",
    "        action_schemas_other = [\n",
    "            \n",
    "            # other agents\n",
    "            ActionSchema(\n",
    "                name=\"pick_other\",\n",
    "                inputs=[\"?rob2\",\"?obj2\",\"?reg3\"],\n",
    "                input_types=[\"robot\",\"physical\",\"region\"],\n",
    "                preconditions=[Not(Atom(\"is_ego\",[\"?rob2\"])), # is not the ego agent\n",
    "                               Atom(\"pick_action\",[\"?rob2\",\"?obj2\"]), # other agents' turn\n",
    "                               Or([Not(Atom(\"in_rob\",[\"?rob2\",REGIONS[0]])),And([Atom(\"in_rob\",[\"?rob2\",REGIONS[0]]),Atom(\"open\",[DOOR])])]), # accesibility of mug: derived predicate\n",
    "                               Atom(\"in_obj\",[\"?obj2\",\"?reg3\"]), # object is in region from where pick is attempted\n",
    "                               Atom(\"in_rob\",[\"?rob2\",\"?reg3\"]), # robot is in region from where pick is attempted\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob2\",\"?obj\"]),[\"?obj\"],[\"physical\"])), # robot hand is free\n",
    "                               ],\n",
    "                verify_effects=[OneOf([Atom(\"holding\",[\"?rob2\",\"?obj2\"]),Atom(\"in_obj\",[\"?obj2\",\"?reg3\"])])]+[OneOf(po) for po in possible_outcomes_pick_place],\n",
    "            ),\n",
    "            \n",
    "            \n",
    "            ActionSchema(\n",
    "                name=\"place_other\",\n",
    "                inputs=[\"?rob2\",\"?obj2\",\"?reg3\"],\n",
    "                input_types=[\"robot\",\"physical\",\"region\"],\n",
    "                preconditions=[Not(Atom(\"is_ego\",[\"?rob2\"])), # is not the ego agent\n",
    "                               Atom(\"place_action\",[\"?rob2\",\"?obj2\"]), # other agents' turn\n",
    "                               Or([Not(Atom(\"in_rob\",[\"?rob2\",REGIONS[0]])),And([Atom(\"in_rob\",[\"?rob2\",REGIONS[0]]),Atom(\"open\",[DOOR])])]), # accessibility of region\n",
    "                               Not(Atom(\"in_obj\",[\"?obj2\",\"?reg3\"])), # object is in region where place is attempted\n",
    "                               Atom(\"in_rob\",[\"?rob2\",\"?reg3\"]), # robot is in region where place is attempted\n",
    "                               Atom(\"holding\",[\"?rob2\",\"?obj2\"]), # robot is holding the object that is to be placed \n",
    "                               Atom(\"stable\",[\"?obj2\",\"?reg3\"]), # region where place is attempted is stable\n",
    "                               ],\n",
    "                verify_effects=[OneOf([Atom(\"holding\",[\"?rob2\",\"?obj2\"]),Atom(\"in_obj\",[\"?obj2\",\"?reg3\"])])]+[OneOf(po) for po in possible_outcomes_pick_place],\n",
    "            ),\n",
    "            \n",
    "            ActionSchema(\n",
    "                name=\"transit_other\",\n",
    "                inputs=[\"?rob2\",\"?reg3\",\"?reg4\"],\n",
    "                input_types=[\"robot\",\"region\",\"region\"],\n",
    "                preconditions=[Not(Atom(\"is_ego\",[\"?rob2\"])), # is not the ego agent\n",
    "                               Atom(\"transit_action\",[\"?rob2\",\"?reg4\"]), # other agents' turn\n",
    "                               Atom(\"in_rob\",[\"?rob2\",\"?reg3\"]),\n",
    "                               Not(Atom(\"in_rob\",[\"?rob2\",\"?reg4\"])),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob2\",\"?obj\"]),[\"?obj\"],[\"physical\"])), # robot hand is free\n",
    "                               ],\n",
    "                verify_effects=[OneOf([Atom(\"in_rob\",[\"?rob2\",reg]) for reg in REGIONS])]+[OneOf(po) for po in possible_outcomes_transit],\n",
    "            ),\n",
    "            \n",
    "            ActionSchema(\n",
    "                name=\"transfer_other\",\n",
    "                inputs=[\"?rob2\",\"?reg3\",\"?reg4\",\"?obj2\"],\n",
    "                input_types=[\"robot\",\"region\",\"region\",\"physical\"],\n",
    "                preconditions=[Not(Atom(\"is_ego\",[\"?rob2\"])), # is not the ego agent\n",
    "                               Atom(\"transfer_action\",[\"?rob2\",\"?obj2\",\"?reg4\"]), # other agents' turn\n",
    "                               Atom(\"in_rob\",[\"?rob2\",\"?reg3\"]),\n",
    "                               Not(Atom(\"in_rob\",[\"?rob2\",\"?reg4\"])),\n",
    "                               Atom(\"holding\",[\"?rob2\",\"?obj2\"]),\n",
    "                               ],\n",
    "                verify_effects=[OneOf([Atom(\"in_rob\",[\"?rob2\",reg]) for reg in REGIONS])]+[OneOf(po) for po in possible_outcomes_transfer],\n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"open_other\",\n",
    "                inputs=[\"?rob2\"],\n",
    "                input_types=[\"robot\"],\n",
    "                preconditions=[Not(Atom(\"is_ego\",[\"?rob2\"])), # is not the ego agent\n",
    "                               Atom(\"open_action\",[\"?rob2\"]), # other agents' turn\n",
    "                               Not(Atom(\"open\",[DOOR])),\n",
    "                               Atom(\"in_rob\",[\"?rob2\",REGIONS[1]]),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob2\",\"?obj\"]),[\"?obj\"],[\"physical\"]))],\n",
    "                verify_effects=[Atom(\"open\",[DOOR])]+[OneOf(po) for po in possible_outcomes_open_close], # TODO: modify     \n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"close_other\",\n",
    "                inputs=[\"?rob2\"],\n",
    "                input_types=[\"robot\"],\n",
    "                preconditions=[Not(Atom(\"is_ego\",[\"?rob2\"])), # is not the ego agent\n",
    "                               Atom(\"close_action\",[\"?rob2\"]), # other agents' turn\n",
    "                               Atom(\"open\",[DOOR]),\n",
    "                               Atom(\"in_rob\",[\"?rob2\",REGIONS[1]]),\n",
    "                               Not(Exists(Atom(\"holding\",[\"?rob2\",\"?obj\"]),[\"?obj\"],[\"physical\"]))],\n",
    "                verify_effects=[Not(Atom(\"open\",[DOOR]))]+[OneOf(po) for po in possible_outcomes_open_close], # TODO: modify\n",
    "            ),\n",
    "            ActionSchema(\n",
    "                name=\"nothing_other\",\n",
    "                inputs=[\"?rob2\"],\n",
    "                input_types=[\"robot\"],\n",
    "                preconditions=[Not(Atom(\"is_ego\",[\"?rob2\"])),\n",
    "                               Atom(\"nothing_action\",[\"?rob2\"])],\n",
    "                verify_effects=[OneOf(po) for po in possible_outcomes],\n",
    "            )\n",
    "            \n",
    "            \n",
    "        ]\n",
    "        \n",
    "        \n",
    "        \n",
    "        action_schemas = []\n",
    "        \n",
    "        for as_other in action_schemas_other:\n",
    "            \n",
    "            as_other_name = as_other.name\n",
    "            \n",
    "            for as_ego in action_schemas_ego:\n",
    "                \n",
    "                as_ego_name = as_ego.name\n",
    "                schema = ActionSchema()\n",
    "                \n",
    "                if (as_other_name == \"transfer_other\" and (as_ego_name == \"transfer_ego\" or as_ego_name == \"pick_ego\" or as_ego_name == \"place_ego\")) or \\\n",
    "                    (as_other_name == \"pick_other\" and (as_ego_name == \"transfer_ego\" or as_ego_name == \"pick_ego\" or as_ego_name == \"place_ego\")) or \\\n",
    "                        (as_other_name == \"open_other\" and as_ego_name == \"open_ego\") or (as_other_name == \"close_other\" and as_ego_name == \"close_ego\") or \\\n",
    "                            (as_other_name == \"place_other\" and (as_ego_name == \"place_ego\" or as_ego_name == \"transfer_ego\")): # not possible under beliefs\n",
    "                    \n",
    "                    continue\n",
    "                \n",
    "                # special cases\n",
    "                # assumption: other agent acts before ego agent\n",
    "                # assumption: pick is confusible with place in the sense nothing happens and vice versa\n",
    "                # transit, transfer regions are confusible, nothing may happen (same region)\n",
    "                # open, close are confusible with each other in the sense nothing happens\n",
    "                # noop observation is deterministic\n",
    "                \n",
    "                # case 1: place, pick\n",
    "                elif as_other_name == \"place_other\" and as_ego_name == \"pick_ego\":\n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = [\"?rob2\",\"?obj1\",\"?reg1\",\"?rob1\"]\n",
    "                    schema.input_types = [\"robot\",\"physical\",\"region\",\"robot\"]\n",
    "                    schema.preconditions = [Atom(\"place_action\",[\"?rob2\",\"?obj1\"]),Atom(\"is_ego\",[\"?rob1\"]),Not(Atom(\"is_ego\",[\"?rob2\"])),Atom(\"holding\",[\"?rob2\",\"?obj1\"]),\n",
    "                                            Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"])),Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]),\n",
    "                                            Atom(\"in_rob\",[\"?rob2\",\"?reg1\"]),Atom(\"stable\",[\"?obj1\",\"?reg1\"]),\n",
    "                                            Or([Not(Atom(\"in_rob\",[\"?rob2\",REGIONS[0]])),And([Atom(\"in_rob\",[\"?rob2\",REGIONS[0]]),Atom(\"open\",[DOOR])])]), # accessibility of region for place\n",
    "                                            ]\n",
    "                    schema.effects = [Not(Atom(\"place_action\",[\"?rob2\",\"?obj1\"]))]\n",
    "                    schema.verify_effects = [OneOf(po) for po in possible_outcomes_pick_place] + [OneOf([Atom(\"holding\",[\"?rob1\",\"?obj1\"]),Atom(\"holding\",[\"?rob2\",\"?obj1\"]),Atom(\"in_obj\",[\"?obj1\",\"?reg1\"])])]\n",
    "                    \n",
    "                # case 2: open, pick\n",
    "                elif as_other_name == \"open_other\" and as_ego_name == \"pick_ego\":\n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = as_other.inputs + as_ego.inputs\n",
    "                    schema.input_types = as_other.input_types + as_ego.input_types\n",
    "                    schema.preconditions = as_other.preconditions + [Atom(\"is_ego\",[\"?rob1\"]), Atom(\"in_obj\",[\"?obj1\",\"?reg1\"]), Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]), \n",
    "                                                                     Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"]))]\n",
    "                    schema.effects = as_other.effects \n",
    "                    schema.verify_effects = as_other.verify_effects + [OneOf([Atom(\"holding\",[\"?rob1\",\"?obj1\"]),Atom(\"in_obj\",[\"?obj1\",\"?reg1\"])])]\n",
    "                    \n",
    "                    \n",
    "                # case 3: open, place\n",
    "                elif as_other_name == \"open_other\" and as_ego_name == \"place_ego\":\n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = as_other.inputs + as_ego.inputs\n",
    "                    schema.input_types = as_other.input_types + as_ego.input_types\n",
    "                    schema.preconditions = as_other.preconditions + [Atom(\"is_ego\",[\"?rob1\"]), Atom(\"holding\",[\"?rob1\",\"?obj1\"]), Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]), \n",
    "                                                                     Atom(\"stable\",[\"?obj1\",\"?reg1\"])]\n",
    "                    schema.effects = as_other.effects\n",
    "                    schema.verify_effects = as_other.verify_effects + [OneOf([Atom(\"holding\",[\"?rob1\",\"?obj1\"]),Atom(\"in_obj\",[\"?obj1\",\"?reg1\"])])]\n",
    "                    \n",
    "                # case 4: open, close\n",
    "                elif as_other_name == \"open_other\" and as_ego_name == \"close_ego\":\n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = as_other.inputs + as_ego.inputs\n",
    "                    schema.input_types = as_other.input_types + as_ego.input_types\n",
    "                    schema.preconditions = as_other.preconditions + as_ego.preconditions\n",
    "                    schema.effects = as_other.effects + as_ego.effects\n",
    "                    schema.verify_effects = [OneOf(po) for po in possible_outcomes_open_close] + as_ego.verify_effects \n",
    "                    \n",
    "                # case 5: close, pick\n",
    "                elif as_other_name == \"close_other\" and as_ego_name == \"pick_ego\":\n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = as_other.inputs + as_ego.inputs\n",
    "                    schema.input_types = as_other.input_types + as_ego.input_types\n",
    "                    schema.preconditions = as_other.preconditions + [Atom(\"is_ego\",[\"?rob1\"]), Not(Atom(\"in_obj\",[\"?obj1\",REGIONS[0]])),\n",
    "                                                                     Not(Exists(Atom(\"holding\",[\"?rob1\",\"?obj\"]),[\"?obj\"],[\"physical\"])), Atom(\"in_rob\",[\"?rob1\",\"?reg1\"])]\n",
    "                    schema.effects = as_other.effects + as_ego.effects # guaranteed pick in region stable but belief inhibits attempting place in region mug\n",
    "                    schema.verify_effects = as_other.verify_effects + as_ego.verify_effects\n",
    "                    \n",
    "                # case 6: close, place\n",
    "                elif as_other_name == \"close_other\" and as_ego_name == \"place_ego\":\n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = as_other.inputs + as_ego.inputs\n",
    "                    schema.input_types = as_other.input_types + as_ego.input_types\n",
    "                    schema.preconditions = as_other.preconditions + [Atom(\"is_ego\",[\"?rob1\"]), Atom(\"holding\",[\"?rob1\",\"?obj1\"]), Atom(\"in_rob\",[\"?rob1\",\"?reg1\"]), \n",
    "                                                                     Not(Atom(\"in_rob\",[\"?rob1\",REGIONS[0]])), Atom(\"stable\",[\"?obj1\",\"?reg1\"])]\n",
    "                    schema.effects = as_other.effects + as_ego.effects # guaranteed place in region stable but belief inhibits attempting place in region mug\n",
    "                    schema.verify_effects = as_other.verify_effects + as_ego.verify_effects\n",
    "                    \n",
    "                # case 7: close, open\n",
    "                elif as_other_name == \"close_other\" and as_ego_name == \"open_ego\":\n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = as_other.inputs + as_ego.inputs\n",
    "                    schema.input_types = as_other.input_types + as_ego.input_types\n",
    "                    schema.preconditions = as_other.preconditions + as_ego.preconditions\n",
    "                    schema.effects = as_other.effects + as_ego.effects\n",
    "                    schema.verify_effects = [OneOf(po) for po in possible_outcomes_open_close] + as_ego.verify_effects\n",
    "                \n",
    "                # regular cases\n",
    "                else: \n",
    "                    \n",
    "                    schema.name = as_other_name+\"*\"+as_ego_name\n",
    "                    schema.inputs = as_other.inputs + as_ego.inputs\n",
    "                    schema.input_types = as_other.input_types + as_ego.input_types\n",
    "                    schema.preconditions = as_other.preconditions + as_ego.preconditions\n",
    "                    schema.effects = as_other.effects + as_ego.effects\n",
    "                    schema.verify_effects = as_other.verify_effects + as_ego.verify_effects   \n",
    "                    \n",
    "                schema.execute_fn = joint_execute_fn\n",
    "                schema.effects_fn = joint_effects_fn\n",
    "\n",
    "                action_schemas.append(schema)\n",
    "                    \n",
    "       \n",
    "        \n",
    "        reward = GOAL\n",
    "\n",
    "        spec = ProblemSpec(\n",
    "            predicates=predicates,\n",
    "            action_schemas=action_schemas,\n",
    "            reward=reward,\n",
    "        )\n",
    "\n",
    "        return spec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create environment and planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planner\n",
    "cfg = load_config(config_file=\"../tampura/config/default.yml\")\n",
    "\n",
    "# Set some print options to print out abstract belief, action, observation, and reward\n",
    "cfg[\"print_options\"] = \"ab,a,o,r\"\n",
    "cfg[\"vis_graph\"] = True\n",
    "# batch size 100, num samples 500 num skeletons 100 works best!!\n",
    "cfg[\"batch_size\"] = 500 #100 \n",
    "cfg[\"num_samples\"] = 500 #500\n",
    "cfg[\"max_steps\"] = 15\n",
    "cfg[\"num_skeletons\"] = 100\n",
    "cfg[\"flat_sample\"] = False # TODO: check; may cause progressive widening\n",
    "\n",
    "\n",
    "# experiment with from_scratch and envelope threshold! comment out next two lines to stick to previous version!\n",
    "\n",
    "cfg['from_scratch'] = False # imp: re-use!!! but graph gets too big\n",
    "cfg[\"envelope_threshold\"] = 0.1 # low, keep executing current plan!\n",
    "\n",
    "# state\n",
    "s = EnvState(holding={ROBOTS[0]:[],ROBOTS[1]:[]},open_door=False,\n",
    "             rob_regions={ROBOTS[0]:REGIONS[-1],ROBOTS[1]:REGIONS[-1]},\n",
    "             obj_regions={MUG:REGIONS[0]},\n",
    "             next_actions=[\"nothing_action-\"+ROBOTS[0],\"nothing_action-\"+ROBOTS[1]])\n",
    "\n",
    "save_dir = os.getcwd()+\"/runs/run{}\".format(time.time())\n",
    "# for robot1\n",
    "# Initialize \n",
    "save_dir_1 = save_dir + \"planner1\"\n",
    "cfg1 = cfg.copy()\n",
    "cfg1['save_dir'] = save_dir_1\n",
    "env1 = ToyDiscrete(config=cfg1)\n",
    "b01, store1= env1.initialize(ego=ROBOTS[0],s=s)\n",
    "# for robot2\n",
    "# Initialize \n",
    "save_dir_2 = save_dir + \"planner2\"\n",
    "cfg2 = cfg.copy()\n",
    "cfg2['save_dir'] = save_dir_2\n",
    "env2 = ToyDiscrete(config=cfg2)\n",
    "b02, store2= env2.initialize(ego=ROBOTS[1],s=s)\n",
    "\n",
    "# Set up logger to print info\n",
    "setup_logger(cfg1[\"save_dir\"], logging.INFO)\n",
    "setup_logger(cfg2[\"save_dir\"], logging.INFO)\n",
    "\n",
    "# Initialize the policy\n",
    "\n",
    "\n",
    "planner1 = TampuraPolicy(config = cfg1, problem_spec = env1.problem_spec)\n",
    "planner2 = TampuraPolicy(config = cfg2, problem_spec = env2.problem_spec)\n",
    "\n",
    "env1.state = copy.deepcopy(s)\n",
    "env2.state = copy.deepcopy(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Planner\n",
    "Make sure symk is installed (see README) before running the Tampura planner.\n",
    "With the default settings, the planner should pick both every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " robot 1 \n",
      "\n",
      "==========t=0==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_stable_mug']), Atom(pred_name='nothing_action', args=['robot_2']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='in_rob', args=['robot_2', 'region_stable_mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] Flat Action Parameter Sampling\n",
      "[TampuraPolicy] Outcome Sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:09<00:00, 51.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TampuraPolicy] MDP Solving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: nothing_other*transit_ego(robot_2, robot_1, region_stable_mug, region_door)\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': []}, open_door=False, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_stable_mug'}, obj_regions={'mug': 'region_mug'}, next_actions=['transit_action-robot_1%region_door', 'nothing_action-robot_2'])\n",
      "\n",
      " robot 2 \n",
      "\n",
      "==========t=0==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_stable_mug']), Atom(pred_name='transit_action', args=['robot_1', 'region_door']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='in_rob', args=['robot_2', 'region_stable_mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] Flat Action Parameter Sampling\n",
      "[TampuraPolicy] Outcome Sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:10<00:00, 45.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TampuraPolicy] MDP Solving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: transit_other*transit_ego(robot_1, region_stable_mug, region_door, robot_2, region_stable_mug, region_door)\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': []}, open_door=False, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_door'}, obj_regions={'mug': 'region_mug'}, next_actions=['transit_action-robot_2%region_door', 'nothing_action-robot_1'])\n",
      "\n",
      " robot 1 \n",
      "\n",
      "==========t=1==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='transit_action', args=['robot_2', 'region_door']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='in_rob', args=['robot_2', 'region_stable_mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n",
      "Action: transit_other*open_ego(robot_2, region_stable_mug, region_door, robot_1)\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': []}, open_door=True, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_door'}, obj_regions={'mug': 'region_mug'}, next_actions=['open_action-robot_1', 'nothing_action-robot_2'])\n",
      "\n",
      " robot 2 \n",
      "\n",
      "==========t=1==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='in_rob', args=['robot_2', 'region_door']), Atom(pred_name='open_action', args=['robot_1']), Atom(pred_name='in_obj', args=['mug', 'region_mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n",
      "Action: open_other*transit_ego(robot_1, robot_2, region_door, region_mug)\n",
      "opened\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': []}, open_door=True, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_mug'}, obj_regions={'mug': 'region_mug'}, next_actions=['transit_action-robot_2%region_mug', 'nothing_action-robot_1'])\n",
      "\n",
      " robot 1 \n",
      "\n",
      "==========t=2==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='in_rob', args=['robot_2', 'region_door']), Atom(pred_name='transit_action', args=['robot_2', 'region_mug']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='open', args=['door'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] Flat Action Parameter Sampling\n",
      "[TampuraPolicy] Outcome Sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:11<00:00, 44.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TampuraPolicy] MDP Solving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: transit_other*nothing_ego(robot_2, region_door, region_mug, robot_1)\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': []}, open_door=True, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_mug'}, obj_regions={'mug': 'region_mug'}, next_actions=['nothing_action-robot_1', 'nothing_action-robot_2'])\n",
      "\n",
      " robot 2 \n",
      "\n",
      "==========t=2==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='nothing_action', args=['robot_1']), Atom(pred_name='in_rob', args=['robot_2', 'region_mug']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='open', args=['door'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] Flat Action Parameter Sampling\n",
      "[TampuraPolicy] Outcome Sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:15<00:00, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TampuraPolicy] MDP Solving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: nothing_other*pick_ego(robot_1, robot_2, mug, region_mug)\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': ['mug']}, open_door=True, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_mug'}, obj_regions={'mug': ''}, next_actions=['pick_action-robot_2%mug', 'nothing_action-robot_1'])\n",
      "\n",
      " robot 1 \n",
      "\n",
      "==========t=3==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='in_rob', args=['robot_2', 'region_mug']), Atom(pred_name='in_obj', args=['mug', 'region_mug']), Atom(pred_name='open', args=['door']), Atom(pred_name='pick_action', args=['robot_2', 'mug'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n",
      "Action: pick_other*close_ego(robot_2, mug, region_mug, robot_1)\n",
      "picked\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': ['mug']}, open_door=False, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_mug'}, obj_regions={'mug': ''}, next_actions=['close_action-robot_1', 'nothing_action-robot_2'])\n",
      "\n",
      " robot 2 \n",
      "\n",
      "==========t=3==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='holding', args=['robot_2', 'mug']), Atom(pred_name='in_rob', args=['robot_2', 'region_mug']), Atom(pred_name='open', args=['door']), Atom(pred_name='close_action', args=['robot_1'])])\n",
      "Reward: 0.0\n",
      "[TampuraPolicy] MDP Solving\n",
      "Action: close_other*nothing_ego(robot_1, robot_2)\n",
      "closed\n",
      "Observation: EnvObservation(holding={'robot_1': [], 'robot_2': ['mug']}, open_door=False, rob_regions={'robot_1': 'region_door', 'robot_2': 'region_mug'}, obj_regions={'mug': ''}, next_actions=['nothing_action-robot_2', 'nothing_action-robot_1'])\n",
      "\n",
      " robot 1 \n",
      "\n",
      "==========t=4==========\n",
      "Abstract Belief: AbstractBelief(items=[Atom(pred_name='in_rob', args=['robot_1', 'region_door']), Atom(pred_name='holding', args=['robot_2', 'mug']), Atom(pred_name='in_rob', args=['robot_2', 'region_mug']), Atom(pred_name='nothing_action', args=['robot_2'])])\n",
      "Reward: 1.0\n",
      "Action: no-op()\n",
      "Observation: None\n",
      "goal achieved\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "b1=b01\n",
    "b2=b02\n",
    "\n",
    "assert env1.problem_spec.verify(store1)\n",
    "assert env2.problem_spec.verify(store2)\n",
    "\n",
    "save_config(planner1.config, planner1.config[\"save_dir\"])\n",
    "save_config(planner2.config, planner2.config[\"save_dir\"])\n",
    "\n",
    "history1 = RolloutHistory(planner1.config)\n",
    "history2 = RolloutHistory(planner2.config)\n",
    "\n",
    "st = time.time()\n",
    "for step in range(100):\n",
    "\n",
    "    # robot 1 acts\n",
    "    env1.state = copy.deepcopy(env2.state) # important!!\n",
    "    s1 = copy.deepcopy(env1.state)\n",
    "    b1.next_actions = s1.next_actions # important!!\n",
    "    a_b1 = b1.abstract(store1)\n",
    "    reward1 = env1.problem_spec.get_reward(a_b1, store1)\n",
    "    # if reward1:\n",
    "    #     print(\"goal achieved\")\n",
    "    #     break\n",
    "    \n",
    "    logging.info(\"\\n robot 1 \")\n",
    "    logging.info(\"\\n\" + (\"=\" * 10) + \"t=\" + str(step) + (\"=\" * 10))\n",
    "    if \"s\" in planner1.print_options:\n",
    "        logging.info(\"State: \" + str(s1))\n",
    "    if \"b\" in planner1.print_options:\n",
    "        logging.info(\"Belief: \" + str(b1))\n",
    "    if \"ab\" in planner1.print_options:\n",
    "        logging.info(\"Abstract Belief: \" + str(a_b1))\n",
    "    if \"r\" in planner1.print_options:\n",
    "        logging.info(\"Reward: \" + str(reward1))\n",
    "    \n",
    "    \n",
    "    action1, info1, store1 = planner1.get_action(b1, store1) # should only call effects functions!!??\n",
    "    \n",
    "    \n",
    "    if \"a\" in planner1.print_options:\n",
    "        logging.info(\"Action: \" + str(action1))\n",
    "\n",
    "    if action1.name == \"no-op\":\n",
    "        bp1 = copy.deepcopy(b1)\n",
    "        observation1 = None\n",
    "    else:\n",
    "        observation1= env1.step(action1, b1, store1) # should call execute function\n",
    "        bp1 = b1.update(action1, observation1, store1)\n",
    "\n",
    "        if planner1.config[\"vis\"]:\n",
    "            env1.vis_updated_belief(bp1, store1)\n",
    "\n",
    "    a_bp1 = bp1.abstract(store1)\n",
    "    history1.add(s1, b1, a_b1, action1, observation1, reward1, info1, store1, time.time() - st)\n",
    "\n",
    "    reward1 = env1.problem_spec.get_reward(a_bp1, store1)\n",
    "    \n",
    "    if \"o\" in planner1.print_options:\n",
    "        logging.info(\"Observation: \" + str(observation1))\n",
    "    if \"sp\" in planner1.print_options:\n",
    "        logging.info(\"Next State: \" + str(env1.state))\n",
    "    if \"bp\" in planner1.print_options:\n",
    "        logging.info(\"Next Belief: \" + str(bp1))\n",
    "    if \"abp\" in planner1.print_options:\n",
    "        logging.info(\"Next Abstract Belief: \" + str(a_bp1))\n",
    "    if \"rp\" in planner1.print_options:\n",
    "        logging.info(\"Next Reward: \" + str(reward1))\n",
    "\n",
    "    # update the belief\n",
    "    b1 = bp1\n",
    "    \n",
    "    # robot 2 acts\n",
    "    env2.state = copy.deepcopy(env1.state) # important!!\n",
    "    s2 = copy.deepcopy(env2.state)\n",
    "    b2.next_actions = s2.next_actions # important!!\n",
    "    a_b2 = b2.abstract(store2)\n",
    "    reward2 = env2.problem_spec.get_reward(a_b2, store2)\n",
    "    \n",
    "    \n",
    "    if reward1 and reward2:\n",
    "        print(\"goal achieved\")\n",
    "        break\n",
    "\n",
    "    logging.info(\"\\n robot 2 \")\n",
    "    logging.info(\"\\n\" + (\"=\" * 10) + \"t=\" + str(step) + (\"=\" * 10))\n",
    "    if \"s\" in planner2.print_options:\n",
    "        logging.info(\"State: \" + str(s2))\n",
    "    if \"b\" in planner1.print_options:\n",
    "        logging.info(\"Belief: \" + str(b2))\n",
    "    if \"ab\" in planner1.print_options:\n",
    "        logging.info(\"Abstract Belief: \" + str(a_b2))\n",
    "    if \"r\" in planner1.print_options:\n",
    "        logging.info(\"Reward: \" + str(reward2))\n",
    "    \n",
    "    \n",
    "    action2, info2, store2 = planner2.get_action(b2, store2) # should only call effects functions!!??\n",
    "    \n",
    "    \n",
    "    if \"a\" in planner2.print_options:\n",
    "        logging.info(\"Action: \" + str(action2))\n",
    "\n",
    "    if action2.name == \"no-op\":\n",
    "        bp2 = copy.deepcopy(b2)\n",
    "        observation2 = None\n",
    "    else:\n",
    "        observation2= env2.step(action2, b2, store2) # should call execute function\n",
    "        bp2 = b2.update(action2, observation2, store2)\n",
    "\n",
    "        if planner2.config[\"vis\"]:\n",
    "            env2.vis_updated_belief(bp2, store2)\n",
    "\n",
    "    a_bp2 = bp2.abstract(store2)\n",
    "    history2.add(s2, b2, a_b2, action2, observation2, reward2, info2, store2, time.time() - st)\n",
    "\n",
    "    reward2 = env2.problem_spec.get_reward(a_bp2, store2)\n",
    "    \n",
    "    if \"o\" in planner2.print_options:\n",
    "        logging.info(\"Observation: \" + str(observation2))\n",
    "    if \"sp\" in planner2.print_options:\n",
    "        logging.info(\"Next State: \" + str(env2.state))\n",
    "    if \"bp\" in planner2.print_options:\n",
    "        logging.info(\"Next Belief: \" + str(bp2))\n",
    "    if \"abp\" in planner2.print_options:\n",
    "        logging.info(\"Next Abstract Belief: \" + str(a_bp2))\n",
    "    if \"rp\" in planner2.print_options:\n",
    "        logging.info(\"Next Reward: \" + str(reward2))\n",
    "\n",
    "    # update the belief\n",
    "    b2 = bp2\n",
    "\n",
    "history1.add(env1.state, bp1, a_bp1, None, None, reward1, info1, store1, time.time() - st)\n",
    "history2.add(env2.state, bp2, a_bp2, None, None, reward2, info2, store2, time.time() - st)\n",
    "    \n",
    "logging.info(\"=\" * 20)\n",
    "\n",
    "env1.wrapup()\n",
    "env2.wrapup()\n",
    "\n",
    "if not planner1.config[\"real_execute\"]:\n",
    "    save_run_data(history1, planner1.config[\"save_dir\"])\n",
    "\n",
    "if not planner2.config[\"real_execute\"]:\n",
    "    save_run_data(history2, planner2.config[\"save_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'class_uncertain',\n",
       " 'planner': 'tampura_policy',\n",
       " 'global_seed': 0,\n",
       " 'vis': False,\n",
       " 'vis_graph': True,\n",
       " 'print_options': 'ab,a,o,r',\n",
       " 'max_steps': 15,\n",
       " 'batch_size': 500,\n",
       " 'num_skeletons': 100,\n",
       " 'flat_sample': False,\n",
       " 'flat_width': 1,\n",
       " 'pwa': 0.2,\n",
       " 'pwk': 3.0,\n",
       " 'envelope_threshold': 0.05,\n",
       " 'num_samples': 500,\n",
       " 'gamma': 0.95,\n",
       " 'decision_strategy': 'prob',\n",
       " 'learning_strategy': 'bayes_optimistic',\n",
       " 'load': None,\n",
       " 'real_camera': False,\n",
       " 'real_execute': False,\n",
       " 'symk_selection': 'unordered',\n",
       " 'symk_direction': 'fw',\n",
       " 'symk_simple': True,\n",
       " 'from_scratch': True,\n",
       " 'save_dir': '/home/am/tamp_multi_agent/notebooks/runs/run1748338845.8320177'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_isaaclab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
